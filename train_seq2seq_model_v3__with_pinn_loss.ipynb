{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtyomShabunin/PINNModels/blob/main/train_seq2seq_model_v3__with_pinn_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "brGGdQOBfHWE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brGGdQOBfHWE",
        "outputId": "bf62f2fa-1350-4140-e922-07c4918ba4e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/RNN-models')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13bd024f-e342-4e0d-8300-060a34382009",
      "metadata": {
        "id": "13bd024f-e342-4e0d-8300-060a34382009"
      },
      "source": [
        "# Seq2Seq нейронная сеть"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gcdegn7RfIVm",
      "metadata": {
        "id": "Gcdegn7RfIVm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3da3bd21-09a3-48a1-819e-77dc3c236d35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3da3bd21-09a3-48a1-819e-77dc3c236d35",
        "outputId": "be35f2ce-d131-4fc2-8258-74f1d13f3e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.7.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.14.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.14.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow==2.22.1 dagshub --quiet\n",
        "!pip install pytorch-lightning\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import callbacks, cli_lightning_logo, LightningDataModule, LightningModule, Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers.mlflow import MLFlowLogger\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch import tensor\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "torch.set_printoptions(precision=3, sci_mode=False)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "from time import time\n",
        "import math\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "import glob\n",
        "import zipfile\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import os\n",
        "import dagshub\n",
        "import mlflow\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "from seqdataset import SequenceDataset\n",
        "\n",
        "from typing import List\n",
        "\n",
        "from numpy import cumsum, ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f7SQCLAboa_U",
      "metadata": {
        "id": "f7SQCLAboa_U"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set seeds\n",
        "def set_seeds(seed: int=42):\n",
        "    \"\"\"Sets random sets for torch operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed to set. Defaults to 42.\n",
        "    \"\"\"\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seeds(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s3LLNIOkkzAd",
      "metadata": {
        "id": "s3LLNIOkkzAd"
      },
      "source": [
        "MLFlow креды"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fzBE-Ksevwfm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "fzBE-Ksevwfm",
        "outputId": "5f0743b0-e745-4ab3-baba-92972b356f92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accessing as pranamodeling\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as pranamodeling\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"pranamodeling/gas-prop-net\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"pranamodeling/gas-prop-net\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository pranamodeling/gas-prop-net initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository pranamodeling/gas-prop-net initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "dagshub.init(\"gas-prop-net\", \"pranamodeling\", mlflow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7c80fe63-83b7-48b6-97bb-794612f2436a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c80fe63-83b7-48b6-97bb-794612f2436a",
        "outputId": "b93e45dc-81a1-498d-fe5f-2e47061d25e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "333805eb-2089-44d9-a41e-6c9df979ce40",
      "metadata": {
        "id": "333805eb-2089-44d9-a41e-6c9df979ce40"
      },
      "source": [
        "## Загрузка и обработка данных для обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1258ac76-22fb-4116-871a-80d0b9a35bf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1258ac76-22fb-4116-871a-80d0b9a35bf8",
        "outputId": "ce3256ec-6ce9-4bf8-a001-1b66fb1069f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Число файлов:  80\n"
          ]
        }
      ],
      "source": [
        "parquetFileList = glob.glob('/content/drive/MyDrive/RNN-models-data/data_4/*.gzip')\n",
        "# parquetFileList = glob.glob('/content/drive/MyDrive/RNN-models-data/data_3/*.gzip')\n",
        "print(\"Число файлов: \", len(parquetFileList))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (pd.read_parquet(parquetFileList[0]).loc[:, ['datetime']].astype('datetime64[ns]').astype('int64')/1000000000).astype('int64')"
      ],
      "metadata": {
        "id": "T5ormipFQu8B"
      },
      "id": "T5ormipFQu8B",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u_N21OAUQ_EP"
      },
      "id": "u_N21OAUQ_EP",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ZgFkAwVaShOt",
      "metadata": {
        "id": "ZgFkAwVaShOt"
      },
      "outputs": [],
      "source": [
        "# parquetFileList = parquetFileList[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "df5d5fb6-703d-4193-9d81-72bfe1172718",
      "metadata": {
        "id": "df5d5fb6-703d-4193-9d81-72bfe1172718"
      },
      "outputs": [],
      "source": [
        "def get_training_and_testing_sets(file_list):\n",
        "    split = 0.7\n",
        "    file_list = [f for f in file_list]\n",
        "    random.shuffle(file_list)\n",
        "    split_index = math.floor(len(file_list) * split)\n",
        "    training = file_list[:split_index]\n",
        "    testing = file_list[split_index:]\n",
        "    return training, testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4bbd359c-bb17-4698-a4e8-1d14f59e5ca7",
      "metadata": {
        "id": "4bbd359c-bb17-4698-a4e8-1d14f59e5ca7"
      },
      "outputs": [],
      "source": [
        "train_files, test_files = get_training_and_testing_sets(parquetFileList)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "881c854f-e82c-4564-91d4-865fcf0917ab",
      "metadata": {
        "id": "881c854f-e82c-4564-91d4-865fcf0917ab"
      },
      "source": [
        "Входные параметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5a6fddad-0b5a-4a0b-803d-6972448a6c52",
      "metadata": {
        "id": "5a6fddad-0b5a-4a0b-803d-6972448a6c52"
      },
      "outputs": [],
      "source": [
        "input_data = [\n",
        "    # 'GTA1.DBinPU.Aldi', # УП дозатора топлива, град\n",
        "    'GTA1.DBinPU.P', # активная мощность генератора, МВт\n",
        "    'GTA1.DBinPU.Ptgpd', # давление топливного газа перед дозатором, МПа\n",
        "    'GTA1.DBinPU.Ttgvh', # температура топливного газа перед дозатороом, С\n",
        "    'GTA1.DBinPU.Ies', # выходной ток в цепи электростартера, А\n",
        "    # 'GTA1.DBinPU.nst', # частота вращения ротора силовой турбины, об/мин\n",
        "    'GTA1.DBinPU.Tn', # температура наружного воздуха, С\n",
        "    'GTA1.DBinPU.Bo', # барометрическое давление, кПа\n",
        "    'GTA1.DBinPU.fi', # относительная влажность наружного воздуха, %\n",
        "    'GTA1.DBinPU.Alzzo', # положение ЗЗО, %\n",
        "    # время\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd3cd566-4d1f-414f-bbe6-68a4b53285c1",
      "metadata": {
        "id": "dd3cd566-4d1f-414f-bbe6-68a4b53285c1"
      },
      "source": [
        "Выходные параметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b80c370d-f734-4647-8ea0-925e198f2c66",
      "metadata": {
        "id": "b80c370d-f734-4647-8ea0-925e198f2c66"
      },
      "outputs": [],
      "source": [
        "output_data = [\n",
        "    # 'GTA1.DBinPU.P', # активная мощность генератора, МВт\n",
        "    'GTA1.DBinPU.Aldi', # УП дозатора топлива, град\n",
        "    'GTA1.DBinPU.ntk', # частота вращения ротора турбокомпрессора, об/мин\n",
        "    'GTA1.DBinPU.nst', # частота вращения ротора силовой турбины, об/мин\n",
        "    # 'GTA1.DBinPU.Ies', # выходной ток в цепи электростартера, А\n",
        "    'GTA1.DBinPU.Alvna', # положение ВНА, град\n",
        "    'GTA1.DBinPU.Qtg', # расход топливного газа, м3/час\n",
        "    'GTA1.DBinPU.Pk', # давление за компрессором, МПа\n",
        "    'GTA1.DBinPU.Tvh1', # температура воздуха перед ГТД, С\n",
        "    'GTA1.DBinPU.Pvh', # давление воздуха перед ГТД, кПа\n",
        "    'GTA1.DBinPU.Tk', # температура воздуха за компрессором, С\n",
        "    'GTA1.DBinPU.Tt', # температура газов за силовой турбиной, С\n",
        "    'GTA1.DBinPU.Pvyhlg', # давление газов за силовой турбиной, кПа\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_no_meas_data = [\n",
        "    'm_air', # расход воздуха через компрессор, кг/с\n",
        "    'etac', # КПД компрессора\n",
        "    'LHV', # теплота сгорания топлива, Дж/кг\n",
        "    't_ggt_in', # температура перед турбиной газогенератора, C\n",
        "    'p_ggt_in', # давление перд турбиной газогенератора, МПа(отн.)\n",
        "    't_ggt_out', # температура за турбиной газогенератора, C\n",
        "    'p_ggt_out', # давление за турбиной газогенератора, МПа(отн.)\n",
        "    'eta_ggt', # КПД турбины газогенератора\n",
        "    'eta_pt', # КПД силовой турбины\n",
        "]"
      ],
      "metadata": {
        "id": "4qLS2a4oKD_N"
      },
      "id": "4qLS2a4oKD_N",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Physics loss"
      ],
      "metadata": {
        "id": "4u7nuUdwKGzj"
      },
      "id": "4u7nuUdwKGzj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель для расчета свойств смесей газов"
      ],
      "metadata": {
        "id": "lVT_3W19WlPb"
      },
      "id": "lVT_3W19WlPb"
    },
    {
      "cell_type": "code",
      "source": [
        "class GasMixturePropertiesNN(nn.Module):\n",
        "    def __init__(self, logged_model_uri: str, logged_info_uri: str, freeze: bool = True):\n",
        "        super().__init__()\n",
        "        # Загрузка модели и информации о нормализации\n",
        "        self.raw_model = mlflow.pyfunc.load_model(logged_model_uri).get_raw_model()\n",
        "\n",
        "        # Заморозка весов\n",
        "        if freeze:\n",
        "            for param in self.raw_model.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        with open(mlflow.artifacts.download_artifacts(logged_info_uri)) as f:\n",
        "            self.model_info = json.load(f)\n",
        "\n",
        "        # Преобразуем mean и std в тензоры\n",
        "        self.register_buffer('input_mean', torch.tensor(self.model_info['scaler_input']['mean_'], dtype=torch.float32))\n",
        "        self.register_buffer('input_std', torch.tensor(self.model_info['scaler_input']['std_'], dtype=torch.float32))\n",
        "        self.register_buffer('output_mean', torch.tensor(self.model_info['scaler_output']['mean_'], dtype=torch.float32))\n",
        "        self.register_buffer('output_std', torch.tensor(self.model_info['scaler_output']['std_'], dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x1: torch.Tensor, x2: torch.Tensor, x3: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            inputs: Tensor размера (batch_size, n_features) — давление, температура/энтальпия, состав смеси и т.д.\n",
        "        Returns:\n",
        "            Tensor размера (batch_size, n_outputs) — физические свойства: T/h, rho, s, mu, lambda, cp\n",
        "        \"\"\"\n",
        "\n",
        "        inputs = torch.cat([x1, x2, x3], axis=1)\n",
        "\n",
        "        # Нормализация\n",
        "        x_norm = (inputs - self.input_mean) / self.input_std\n",
        "\n",
        "        # Предсказание\n",
        "        y_norm = self.raw_model(x_norm)\n",
        "\n",
        "        # Обратная нормализация\n",
        "        y = y_norm * self.output_std + self.output_mean\n",
        "\n",
        "        return {key:y[:,i:i+1] for i, key in enumerate(self.model_info['output'])}"
      ],
      "metadata": {
        "id": "XmSepJ-2V_Rj"
      },
      "id": "XmSepJ-2V_Rj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация моделей\n",
        "gas_pHX = GasMixturePropertiesNN(\n",
        "    logged_model_uri='runs:/7febe97b33db4e978445b2290c9453d1/mdllol',\n",
        "    logged_info_uri='mlflow-artifacts:/e7cc815685774faa9f6b047a083f2220/7febe97b33db4e978445b2290c9453d1/artifacts/info.json'\n",
        ")\n",
        "\n",
        "gas_pTX = GasMixturePropertiesNN(\n",
        "    logged_model_uri='runs:/71abefa7c4d5421abbb48f9dd3b7f1b8/mdllol',\n",
        "    logged_info_uri='mlflow-artifacts:/814e64636dca42cfbac0984ece9bc5fd/71abefa7c4d5421abbb48f9dd3b7f1b8/artifacts/info.json'\n",
        ")\n",
        "\n",
        "gas_pSX = GasMixturePropertiesNN(\n",
        "    logged_model_uri='runs:/6511acddd9874890ba90d6c889756c81/mdllol',\n",
        "    logged_info_uri='mlflow-artifacts:/25c2c06c1c7f43d3bb10a131022afe84/6511acddd9874890ba90d6c889756c81/artifacts/info.json'\n",
        ")"
      ],
      "metadata": {
        "id": "WF338oxkWmdb"
      },
      "id": "WF338oxkWmdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GYzg2-tvWmjR"
      },
      "id": "GYzg2-tvWmjR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "У модели должно быть два output, один с измеряемыми данными, другой с неизмеряемыми.  \n",
        "Дополнительные выходные параметры: расход воздуха, КПД компрессора, низшая теплота сгорания топлива, КПД турбины газогенератора, температура за турбиной газогенератора, давление за турбиной газогенератора   \n",
        "В физические ограничения можно записать баланс мощности"
      ],
      "metadata": {
        "id": "xA29L23zPiG3"
      },
      "id": "xA29L23zPiG3"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_time_derivatives(y_pred, t):\n",
        "    dYdt = torch.autograd.grad(\n",
        "        outputs=y_pred,\n",
        "        inputs=t,\n",
        "        grad_outputs=torch.ones_like(y_pred),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "    return dYdt"
      ],
      "metadata": {
        "id": "AzQCF7OVPJcv"
      },
      "id": "AzQCF7OVPJcv",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def physics_loss(t, x_input, y_pred):\n",
        "\n",
        "    # Расчет состава воздуха\n",
        "    # Эталонный состав воздуха\n",
        "    # Oxygen, Argon, Water, Carbondioxide, Nitrogen\n",
        "    # Массовый состав (массовые доли)\n",
        "    Xref = torch.tensor([0.23, 0.005, 0.015, 1e-6, 0.75-1e-6])\n",
        "    # Мольные массы (кг/моль)\n",
        "    MMX = torch.tensor([0.0319988, 0.039948, 0.01801528, 0.0440095, 0.0280134])\n",
        "\n",
        "    # Число молей каждого компонента (масса / мольная масса)\n",
        "    mol_numbers = Xref / MMX\n",
        "\n",
        "    # Суммарное количество молей\n",
        "    mol_total = mol_numbers.sum()\n",
        "\n",
        "    # Мольные доли\n",
        "    Yref = mol_numbers / mol_total\n",
        "\n",
        "    # Распаковка\n",
        "    y_meas, y_no_meas = y_pred\n",
        "\n",
        "    tamb, pamb, RH = input_data[..., 4], input_data[..., 5], input_data[..., 6]\n",
        "\n",
        "    # tamb = torch.tensor([15])\n",
        "    # pamb = torch.tensor([101325])\n",
        "    # RH = torch.tensor([0.8])\n",
        "\n",
        "\n",
        "    Psat_a = 0.6121*torch.exp((18.678-(tamb)/234.5)*(tamb)/(257.14+tamb))*1e3;\n",
        "    Psat_b = 0.61115*torch.exp((23.036-(tamb)/333.7)*(tamb)/(279.82+tamb))*1e3;\n",
        "\n",
        "    Psat = torch.where(tamb > 0, Psat_a, Psat_b)\n",
        "\n",
        "    Ph2o = RH * Psat\n",
        "    yh2o = Ph2o / pamb\n",
        "\n",
        "    Y = Yref*(1-yh2o)/(1-Yref[3])\n",
        "    Y[2] = yh2o\n",
        "\n",
        "    numerator = Y * MMX\n",
        "    denominator = numerator.sum(dim=-1, keepdim=True)\n",
        "    X_air = numerator / denominator\n",
        "\n",
        "    # Компрессор\n",
        "\n",
        "    pc_out, Tc_out = y_meas[..., 5], y_meas[..., 8]\n",
        "    pc_in, Tc_in = y_meas[..., 5], y_meas[..., 8]\n",
        "    # даления необходимо привести к единой размерности\n",
        "\n",
        "    state_c_in = gas_pSX(pc_in, Tc_in+273.15, X_air)\n",
        "    state_c_out = gas_pTX(pc_out, Tc_out+273.15, X_air)\n",
        "    state_c_iso = gas_pSX(pc_out, state_in['s'], X_air)\n",
        "\n",
        "    eta_c = (state_c_iso['h'] - state_c_in['h']) / (state_c_out['h'] - state_c_in['h'])\n",
        "\n",
        "    m_air_hat, etac_hat = y_no_meas[..., 0], y_no_meas[..., 1]\n",
        "\n",
        "    Pc = m_air_hat * (state_c_out['h'] - state_c_in['h']) # Возможно имеет смысл учесть механические потери\n",
        "\n",
        "\n",
        "    # КАМЕРА СГОРАНИЯ\n",
        "\n",
        "    # Молярные массы, кг/моль\n",
        "    MM = {\n",
        "        'CH4': 0.01604246,\n",
        "        'O2':  0.0319988,\n",
        "        'H2O': 0.01801528,\n",
        "        'CO2': 0.0440095\n",
        "    }\n",
        "\n",
        "    # Сопоставление индексов компонентов в воздухе\n",
        "    IDX = {\n",
        "        'O2': 0,\n",
        "        'Ar': 1,\n",
        "        'H2O': 2,\n",
        "        'CO2': 3,\n",
        "        'N2': 4\n",
        "    }\n",
        "\n",
        "    # Сопоставление индексов компонентов в топливе\n",
        "    FUEL_IDX = {\n",
        "        'N2': 0,\n",
        "        'CO2': 1,\n",
        "        'CH4': 2\n",
        "    }\n",
        "\n",
        "    # Эталонный состав топлива (N2, CO2, CH4)\n",
        "    X_fuel = torch.tensor([0.02,0.012,0.968])\n",
        "\n",
        "\n",
        "    m_fuel = y_meas[..., 4] # нужен пересчет объемного расхода в массовый\n",
        "    LHV_hat = y_no_meas[..., 2]\n",
        "    LHV = 33500.0e3 # Заданное значение\n",
        "\n",
        "    # Массы компонентов воздуха (5 компонентов)\n",
        "    M_air = m_air_hat * X_air\n",
        "\n",
        "    # Преобразуем топливо в 5-компонентный вектор\n",
        "    M_fuel = torch.zeros_like(M_air)  # (batch, 5)\n",
        "    M_fuel[:, IDX['N2']]  = m_fuel * X_fuel[:, FUEL_IDX['N2']]\n",
        "    M_fuel[:, IDX['CO2']] = m_fuel * X_fuel[:, FUEL_IDX['CO2']]\n",
        "    m_CH4 = m_fuel * X_fuel[:, FUEL_IDX['CH4']].unsqueeze(1)  # (batch, 1)\n",
        "\n",
        "    # Молярный расход CH4 (кмоль/с)\n",
        "    n_CH4 = m_CH4 / MM['CH4']\n",
        "\n",
        "    # учет ограниченного кислорода\n",
        "    m_O2_avail = M_air[:, IDX['O2']].unsqueeze(1)\n",
        "    m_O2_needed = 2 * n_CH4 * MM['O2']\n",
        "    lambda_ = m_O2_avail / (m_O2_needed + 1e-8)\n",
        "    combustion_ratio = torch.clamp(lambda_, max=1.0, min=0.0)\n",
        "    n_CH4_reacted = n_CH4 * combustion_ratio\n",
        "    n_CH4_unburned = n_CH4 * (1.0 - combustion_ratio)\n",
        "    m_CH4_unburned = n_CH4_unburned * MM['CH4']\n",
        "\n",
        "    # Массы продуктов реакции\n",
        "    m_O2_react = 2 * n_CH4_reacted * MM['O2']\n",
        "    m_H2O_prod = 2 * n_CH4_reacted * MM['H2O']\n",
        "    m_CO2_prod = 1 * n_CH4_reacted * MM['CO2']\n",
        "\n",
        "    # Масса компонентов за камерой сгорания\n",
        "    M_out = M_air + M_fuel\n",
        "    M_out -= m_O2_react.squeeze(1)\n",
        "    M_out += m_H2O_prod.squeeze(1)\n",
        "    M_out += m_CO2_prod.squeeze(1)\n",
        "\n",
        "    # Массовый состав выхлопных газов\n",
        "    X_flue = M_out / M_out.sum(dim=1, keepdim=True)\n",
        "\n",
        "    # Расход выхлопных газов\n",
        "    m_flue = m_air_hat + m_fuel\n",
        "\n",
        "    # Уравнение сохранения энергии для камеры сгорания\n",
        "    h_ggt_in = (m_air_hat * state_c_out['h'] + m_fuel * LHV_hat) / m_flue\n",
        "\n",
        "    # Давление за камерой сгорания\n",
        "    p_ggt_in = pc_out * (1 - 0.05)\n",
        "\n",
        "    state_ggt_in = gas_pHX(p_ggt_in, h_ggt_in, X_flue)\n",
        "    t_ggt_in = state_ggt_in['T']\n",
        "\n",
        "    t_ggt_in_hat, p_ggt_in_hat = y_no_meas[..., 3], y_no_meas[..., 4]\n",
        "\n",
        "    # ТУРБИНА ГАЗОГЕНЕРАТОРА\n",
        "\n",
        "    # Давление за камерой сгорания\n",
        "    p_ggt_in = pc_out * (1 - 0.05)\n",
        "\n",
        "    state_ggt_in = gas_pTX(p_ggt_in_hat, t_ggt_in_hat, X_flue)\n",
        "    t_ggt_out_hat, p_ggt_out_hat = y_no_meas[..., 5], y_no_meas[..., 6]\n",
        "    state_ggt_out = gas_pTX(p_ggt_out_hat, t_ggt_out_hat, X_flue)\n",
        "\n",
        "    state_ggt_iso = gas_pSX(p_ggt_in, state_ggt_in['s'], X_flue)\n",
        "    eta_ggt = (state_ggt_in['h'] - state_ggt_out['h']) / (state_ggt_in['h'] - state_ggt_iso['h'])\n",
        "\n",
        "    eta_ggt_hat = y_no_meas[..., 7]\n",
        "    Pggt = m_flue * (state_ggt_in['h'] - state_ggt_out['h']) # Возможно имеет смысл учесть механические потери\n",
        "\n",
        "    # ГАЗОГЕНЕРАТОР\n",
        "    # Сюда можно добавить уровнение с производной по скорости вращения ротора ГГ\n",
        "\n",
        "\n",
        "    # СИЛОВАЯ ТУРБИНА\n",
        "\n",
        "    Tpt_out, ppt_out = y_meas[..., 9], y_meas[..., 10]\n",
        "    state_pt_out = gas_pTX(ppt_out, Tpt_out, X_flue)\n",
        "    state_pt_iso = gas_pSX(p_ggt_out, state_ggt_out['s'], X_flue)\n",
        "    eta_pt = (state_ggt_out['h'] - state_pt_iso['h']) / (state_ggt_out['h'] - state_pt_iso['h'])\n",
        "    eta_pt_hat = y_no_meas[..., 8]\n",
        "\n",
        "    Ppt_hat = m_flue * (state_pt_in['h'] - state_pt_out['h']) # Возможно имеет смысл учесть механические потери\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Losses\n",
        "    # MSE(eta_c, etac_hat),\n",
        "    # MSE(LHV, LHV_hat),\n",
        "    # MSE(t_ggt_in, t_ggt_in_hat)\n",
        "    # MSE(p_ggt_in, p_ggt_in_hat)\n",
        "    # MSE(t_ggt_out, t_ggt_out_hat)\n",
        "    # MSE(p_ggt_out, p_ggt_out_hat)\n",
        "    # MSE(eta_ggt, eta_ggt_hat)\n",
        "    # MSE(Pggt, Pc)\n",
        "    # MSE(eta_pt, eta_pt_hat)\n",
        "    # MSE(Ppt, Ppt_hat) # нужно учесть что при мощности равной нулю ошибка не должна учитываться"
      ],
      "metadata": {
        "id": "nPQy_x2gKEVf"
      },
      "id": "nPQy_x2gKEVf",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8yoJ7wPNkcv7"
      },
      "id": "8yoJ7wPNkcv7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d3KofzsqpgNf"
      },
      "id": "d3KofzsqpgNf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQy3HzKFpsJC"
      },
      "id": "EQy3HzKFpsJC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wrEU8m1sj-AW"
      },
      "id": "wrEU8m1sj-AW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPNlGTinj-Fd",
        "outputId": "5cd994ed-07fa-4cbb-8df2-17f978e04b64"
      },
      "id": "mPNlGTinj-Fd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(34.918)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6412673-e342-4d45-bb46-5fbc6c047ddf",
      "metadata": {
        "id": "f6412673-e342-4d45-bb46-5fbc6c047ddf"
      },
      "source": [
        "## Нормализация данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-uf6T2Tkooi9",
      "metadata": {
        "id": "-uf6T2Tkooi9"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# scaler_input = StandardScaler()\n",
        "# scaler_output = StandardScaler()\n",
        "\n",
        "# scaler_input = MinMaxScaler()\n",
        "# scaler_output = MinMaxScaler()\n",
        "\n",
        "# for file in tqdm(parquetFileList):\n",
        "#     df = pd.read_parquet(file)\n",
        "\n",
        "#     input_values = df[input_data]\n",
        "#     output_values = df[output_data]\n",
        "\n",
        "#     scaler_input.partial_fit(input_values)\n",
        "#     input_values = scaler_input.transform(input_values)\n",
        "\n",
        "#     scaler_output.partial_fit(output_values)\n",
        "#     output_values = scaler_output.transform(output_values)\n",
        "\n",
        "# joblib.dump(scaler_input, \"/content/drive/MyDrive/RNN-models/scaler_input_3.pkl\")\n",
        "# joblib.dump(scaler_output, \"/content/drive/MyDrive/RNN-models/scaler_output_3.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "3c9b5712-cdb0-459a-a1b3-c5a65824132d",
      "metadata": {
        "id": "3c9b5712-cdb0-459a-a1b3-c5a65824132d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e0c9a3-b6f4-4b4b-f210-e298257d70d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "scaler_input = joblib.load(\"/content/drive/MyDrive/RNN-models/scaler_input_2.pkl\")\n",
        "scaler_output = joblib.load(\"/content/drive/MyDrive/RNN-models/scaler_output_2.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "0FRcHWdsKCxf",
      "metadata": {
        "id": "0FRcHWdsKCxf"
      },
      "outputs": [],
      "source": [
        "prep_input_info ={}\n",
        "prep_output_info = {}\n",
        "prep_input_info['scaler_input'] = {\"min_\": scaler_input.data_min_.tolist(), \"max_\": scaler_input.data_max_.tolist()}\n",
        "prep_output_info['scaler_output'] = {\"min_\": scaler_output.data_min_.tolist(), \"max_\": scaler_output.data_max_.tolist()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "9TtiSN9oKwOt",
      "metadata": {
        "id": "9TtiSN9oKwOt"
      },
      "outputs": [],
      "source": [
        "class SequenceDatasetForRNN(Dataset):\n",
        "\n",
        "    '''\n",
        "        shift - смещение входных данных decodera относительно энкодера\n",
        "        при shift = -1 первый входной вектор декодара равен последнему вектору энкодера\n",
        "    '''\n",
        "    def __init__(\n",
        "                self,\n",
        "                files:List,\n",
        "                input_data,\n",
        "                output_data,\n",
        "                encoder_length=60,\n",
        "                decoder_length=300,\n",
        "                scaler_input = None,\n",
        "                scaler_output = None,\n",
        "                shift=0,\n",
        "                step=1):\n",
        "\n",
        "      self.files = files\n",
        "      self.encoder_length = encoder_length\n",
        "      self.decoder_length = decoder_length\n",
        "      self.scaler_input = scaler_input\n",
        "      self.scaler_output = scaler_output\n",
        "      self.shift = shift\n",
        "      self.step = step\n",
        "\n",
        "      self.len_of_files = []\n",
        "      for file in self.files:\n",
        "        df = pd.read_parquet(file)\n",
        "\n",
        "        self.len_of_files.append(\n",
        "            round((df.shape[0]-self.encoder_length-self.decoder_length-self.shift+1)/self.step))\n",
        "\n",
        "      self.cum_sum_len_of_files = np.cumsum(np.array(self.len_of_files))\n",
        "\n",
        "    def __len__(self):\n",
        "      return sum(self.len_of_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      file_index = (idx > self.cum_sum_len_of_files).sum()\n",
        "      if file_index == 0:\n",
        "        idx_in_file = idx\n",
        "      else:\n",
        "        idx_in_file = idx - self.cum_sum_len_of_files[file_index-1]\n",
        "\n",
        "      df = pd.read_parquet(self.files[file_index])\n",
        "      df = df.iloc[idx_in_file:idx_in_file+self.encoder_length+self.decoder_length+self.shift+1,:]\n",
        "\n",
        "      input_values = df[input_data]\n",
        "      output_values = df[output_data]\n",
        "\n",
        "      if self.scaler_input:\n",
        "          input_values = self.scaler_input.transform(input_values)\n",
        "      else:\n",
        "          input_values = input_values.to_numpy()\n",
        "      if self.scaler_output:\n",
        "          output_values = self.scaler_output.transform(output_values)\n",
        "      else:\n",
        "          output_values = output_values.to_numpy()\n",
        "\n",
        "      input = torch.tensor(input_values,dtype=torch.float32)\n",
        "      output = torch.tensor(output_values,dtype=torch.float32)\n",
        "\n",
        "      encoder_inputs = torch.cat(\n",
        "          (input[:self.encoder_length, :],\n",
        "            output[:self.encoder_length, :]), 1)\n",
        "      decoder_inputs = input[self.encoder_length + self.shift:self.encoder_length + self.decoder_length + self.shift, :]\n",
        "      decoder_state_inputs = output[self.encoder_length + self.shift:self.encoder_length + self.decoder_length + self.shift, :]\n",
        "      target = output[self.encoder_length + self.shift:self.encoder_length + self.decoder_length + (self.shift + 1), :]\n",
        "\n",
        "      return encoder_inputs, decoder_inputs, decoder_state_inputs, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "STznz8OEbMEB",
      "metadata": {
        "id": "STznz8OEbMEB"
      },
      "outputs": [],
      "source": [
        "# for f in parquetFileList:\n",
        "#   df = pd.read_parquet(f)\n",
        "#   print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TUz1dgz3bMLR",
      "metadata": {
        "id": "TUz1dgz3bMLR"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_parquet(parquetFileList[0])\n",
        "# df = df.iloc[3:6,:]\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NXbXJB9D4Ftu",
      "metadata": {
        "id": "NXbXJB9D4Ftu"
      },
      "outputs": [],
      "source": [
        "# import pyarrow.parquet as pq\n",
        "# parquet_file = pq.ParquetFile(parquetFileList[0])\n",
        "# parquet_file.read_row_group(0)\n",
        "# parquet_file.num_row_groups"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e6fa061-4428-403f-b9a6-19458d217533",
      "metadata": {
        "id": "8e6fa061-4428-403f-b9a6-19458d217533"
      },
      "source": [
        "# Модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fF_MQ5fJ4CwE",
      "metadata": {
        "id": "fF_MQ5fJ4CwE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9I11dYdtZq3R",
      "metadata": {
        "id": "9I11dYdtZq3R"
      },
      "source": [
        "## Модель Seq2Seq\n",
        "В данной реализации на вход декодера подаются только управляющие воздействия, и внешние воздействия. На выходе декода получаем значения показаний датчиков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "060ba0f5-04d6-4656-8bbd-f0669e9e98fb",
      "metadata": {
        "id": "060ba0f5-04d6-4656-8bbd-f0669e9e98fb"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, enc_feature_size, hidden_size, num_gru_layers, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.enc_feature_size = enc_feature_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_gru_layers = num_gru_layers\n",
        "\n",
        "    self.gru = nn.GRU(enc_feature_size, hidden_size, num_gru_layers,\n",
        "                      batch_first=True, dropout=dropout)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    output, hidden = self.gru(inputs)\n",
        "\n",
        "    return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderVanilla(nn.Module):\n",
        "    def __init__(self, dec_feature_size, dec_target_size,\n",
        "                 hidden_size, num_gru_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dec_feature_size = dec_feature_size\n",
        "        self.dec_target_size = dec_target_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_gru_layers = num_gru_layers\n",
        "\n",
        "        self.gru = nn.GRU(dec_feature_size, hidden_size, num_gru_layers,\n",
        "                          batch_first=True, dropout=dropout)\n",
        "        self.out = nn.Linear(hidden_size, dec_target_size)\n",
        "\n",
        "    def forward(self, inputs, hidden, enc_outputs):\n",
        "\n",
        "        output, hidden = self.gru(inputs, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "5s8KXtrVYeOX"
      },
      "id": "5s8KXtrVYeOX",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size, num_gru_layers):\n",
        "        super().__init__()\n",
        "        # NOTE: the hidden size for the output of attn (and input of v) can actually be any number\n",
        "        # Also, using two layers allows for a non-linear act func inbetween\n",
        "        self.attn = nn.Linear(2 * hidden_size, hidden_size)\n",
        "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
        "\n",
        "    def forward(self, decoder_hidden_final_layer, encoder_outputs):\n",
        "        # decoder_hidden_final_layer: (batch size, hidden size)\n",
        "        # encoder_outputs: (batch size, input seq len, hidden size)\n",
        "\n",
        "        # Repeat decoder hidden state input seq len times\n",
        "        hidden = decoder_hidden_final_layer.unsqueeze(1).repeat(1, encoder_outputs.shape[1], 1)\n",
        "\n",
        "        # Compare decoder hidden state with each encoder output using a learnable tanh layer\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "\n",
        "        # Then compress into single values for each comparison (energy)\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "\n",
        "        # Then softmax so the weightings add up to 1\n",
        "        weightings = F.softmax(attention, dim=1)\n",
        "\n",
        "        # weightings: (batch size, input seq len)\n",
        "        return weightings"
      ],
      "metadata": {
        "id": "NFOC0Uz0f2hh"
      },
      "id": "NFOC0Uz0f2hh",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderWithAttention(nn.Module):\n",
        "    def __init__(self, dec_feature_size, dec_target_size,\n",
        "                 hidden_size, num_gru_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dec_feature_size = dec_feature_size\n",
        "        self.dec_target_size = dec_target_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_gru_layers = num_gru_layers\n",
        "\n",
        "        self.attention_model = Attention(hidden_size, num_gru_layers)\n",
        "        self.gru = nn.GRU(dec_feature_size + hidden_size, hidden_size, num_gru_layers,\n",
        "                          batch_first=True, dropout=dropout)\n",
        "        self.out = nn.Linear(hidden_size, dec_target_size)\n",
        "\n",
        "    def forward(self, inputs, hidden, enc_outputs):\n",
        "\n",
        "        weightings = self.attention_model(hidden[-1], enc_outputs)\n",
        "        weighted_sum = torch.bmm(weightings.unsqueeze(1), enc_outputs)\n",
        "\n",
        "\n",
        "        output, hidden = self.gru(torch.cat((inputs, weighted_sum), dim=2), hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "mzlTU3JDgr3F"
      },
      "id": "mzlTU3JDgr3F",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(LightningModule):\n",
        "    def __init__(self, encoder, decoder, lr: float = 1e-3, teacher_force_probability: int = 0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers_size = {\n",
        "            'enc_feature_size': encoder.enc_feature_size,\n",
        "            'enc_hidden_size': encoder.hidden_size,\n",
        "            'enc_num_gru_layers': encoder.num_gru_layers,\n",
        "            'dec_feature_size': decoder.dec_feature_size,\n",
        "            'dec_target_size': decoder.dec_target_size,\n",
        "            'dec_hidden_size': decoder.hidden_size,\n",
        "            'dec.num_gru_layers': decoder.num_gru_layers\n",
        "            }\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.lr = lr\n",
        "        self.teacher_force_probability = teacher_force_probability\n",
        "\n",
        "\n",
        "    def forward(self, enc_inputs, dec_inputs, dec_state_inputs=None,\n",
        "                teacher_force_probability=0):\n",
        "\n",
        "        # Store outputs\n",
        "        outputs = [None for _ in range(dec_inputs.shape[1])]\n",
        "\n",
        "        enc_outputs, hidden = self.encoder(enc_inputs)\n",
        "        # outputs[0] = self.fc(output[:,-1,:])[:,None,:]\n",
        "\n",
        "        for t in range(dec_inputs.shape[1]):\n",
        "          teacher_force = random.random() < teacher_force_probability\n",
        "\n",
        "          input_at_t = torch.cat(\n",
        "              (dec_inputs[:,t,:][:,np.newaxis,:], dec_state_inputs[:,t,:][:,np.newaxis,:]), 2) if teacher_force or t == 0 else torch.cat(\n",
        "                  (dec_inputs[:,t,:][:,np.newaxis,:], outputs[t-1]), 2)\n",
        "\n",
        "          output, hidden = self.decoder(input_at_t, hidden, enc_outputs)\n",
        "\n",
        "          outputs[t] = output\n",
        "\n",
        "        outputs = torch.stack(outputs, dim = 1)\n",
        "        outputs = torch.squeeze(outputs)\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._common_step(batch, batch_idx, self.teacher_force_probability, \"train\")\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self._common_step(batch, batch_idx, 0, \"val\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                  factor=0.3, patience=3,\n",
        "                                                  threshold=0.0001)\n",
        "\n",
        "        # return optimizer\n",
        "        return {\n",
        "           'optimizer': optimizer,\n",
        "           'lr_scheduler': scheduler,\n",
        "           'monitor': 'train_loss'\n",
        "       }\n",
        "\n",
        "    def _common_step(self, batch, batch_idx, teacher_force_probability, stage: str):\n",
        "        encoder_inputs, decoder_inputs, decoder_state_inputs, target = batch\n",
        "        encoder_inputs = encoder_inputs.to(device)\n",
        "        decoder_inputs = decoder_inputs.to(device)\n",
        "        decoder_state_inputs = decoder_state_inputs.to(device)\n",
        "\n",
        "        target = target[:,1:,:]\n",
        "        y = target.to(device)\n",
        "\n",
        "        # teacher_force_probability = round(10 * teacher_force_probability / max(1, self.current_epoch)) / 10\n",
        "        teacher_force_probability = max(0, teacher_force_probability - 0.025 * max(1, self.current_epoch) * teacher_force_probability)\n",
        "\n",
        "        y_hat, hidden = self(encoder_inputs, decoder_inputs,\n",
        "                             decoder_state_inputs, teacher_force_probability)\n",
        "\n",
        "        # loss = nn.L1Loss(y_hat, y)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        self.log(f\"{stage}_loss\", loss, on_step=True)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "R409j4qSYeYp"
      },
      "id": "R409j4qSYeYp",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq_onlyx_decoder(LightningModule):\n",
        "    def __init__(self, encoder, decoder, lr: float = 1e-3, teacher_force_probability: int = 0, encoder_shufle: int = 0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers_size = {\n",
        "            'enc_feature_size': encoder.enc_feature_size,\n",
        "            'enc_hidden_size': encoder.hidden_size,\n",
        "            'enc_num_gru_layers': encoder.num_gru_layers,\n",
        "            'dec_feature_size': decoder.dec_feature_size,\n",
        "            'dec_target_size': decoder.dec_target_size,\n",
        "            'dec_hidden_size': decoder.hidden_size,\n",
        "            'dec.num_gru_layers': decoder.num_gru_layers\n",
        "            }\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.lr = lr\n",
        "        self.teacher_force_probability = teacher_force_probability\n",
        "        self.encoder_shufle = encoder_shufle\n",
        "\n",
        "\n",
        "    def forward(self, enc_inputs, dec_inputs, dec_state_inputs=None,\n",
        "                teacher_force_probability=0):\n",
        "\n",
        "        # Store outputs\n",
        "        outputs = [None for _ in range(dec_inputs.shape[1])]\n",
        "\n",
        "        enc_outputs, hidden = self.encoder(enc_inputs)\n",
        "        # outputs[0] = self.fc(output[:,-1,:])[:,None,:]\n",
        "\n",
        "        for t in range(dec_inputs.shape[1]):\n",
        "          # teacher_force = random.random() < teacher_force_probability\n",
        "\n",
        "          input_at_t = dec_inputs[:,t,:][:,np.newaxis,:]\n",
        "          output, hidden = self.decoder(input_at_t, hidden, enc_outputs)\n",
        "\n",
        "          outputs[t] = output\n",
        "\n",
        "        outputs = torch.stack(outputs, dim = 1)\n",
        "        outputs = torch.squeeze(outputs)\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._common_step(batch, batch_idx, self.teacher_force_probability, \"train\")\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self._common_step(batch, batch_idx, 0, \"val\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                  factor=0.3, patience=3,\n",
        "                                                  threshold=0.0001)\n",
        "\n",
        "        # return optimizer\n",
        "        return {\n",
        "           'optimizer': optimizer,\n",
        "           'lr_scheduler': scheduler,\n",
        "           'monitor': 'train_loss'\n",
        "       }\n",
        "\n",
        "    def _common_step(self, batch, batch_idx, teacher_force_probability, stage: str):\n",
        "        encoder_inputs, decoder_inputs, decoder_state_inputs, target = batch\n",
        "\n",
        "        if  random.random() < self.encoder_shufle:\n",
        "          encoder_inputs = encoder_inputs[torch.randperm(encoder_inputs.shape[0])]\n",
        "\n",
        "        encoder_inputs = encoder_inputs.to(device)\n",
        "        decoder_inputs = decoder_inputs.to(device)\n",
        "        decoder_state_inputs = decoder_state_inputs.to(device)\n",
        "\n",
        "        target = target[:,1:,:]\n",
        "        y = target.to(device)\n",
        "\n",
        "        # teacher_force_probability = round(10 * teacher_force_probability / max(1, self.current_epoch)) / 10\n",
        "        teacher_force_probability = max(0, teacher_force_probability - 0.025 * max(1, self.current_epoch) * teacher_force_probability)\n",
        "\n",
        "        y_hat, hidden = self(encoder_inputs, decoder_inputs,\n",
        "                             decoder_state_inputs, teacher_force_probability)\n",
        "\n",
        "        # loss = nn.L1Loss(y_hat, y)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        self.log(f\"{stage}_loss\", loss, on_step=True)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "XKabC94UZzKB"
      },
      "id": "XKabC94UZzKB",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqDistrib(LightningModule):\n",
        "    def __init__(self, encoder, decoder, lr: float = 1e-3, teacher_force_probability: int = 0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers_size = {\n",
        "            'enc_feature_size': encoder.enc_feature_size,\n",
        "            'enc_hidden_size': encoder.hidden_size,\n",
        "            'enc_num_gru_layers': encoder.num_gru_layers,\n",
        "            'dec_feature_size': decoder.dec_feature_size,\n",
        "            'dec_target_size': decoder.dec_target_size,\n",
        "            'dec_hidden_size': decoder.hidden_size,\n",
        "            'dec.num_gru_layers': decoder.num_gru_layers\n",
        "            }\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.lr = lr\n",
        "        self.teacher_force_probability = teacher_force_probability\n",
        "\n",
        "\n",
        "    def forward(self, enc_inputs, dec_inputs, dec_state_inputs=None,\n",
        "                teacher_force_probability=0):\n",
        "\n",
        "        # Store outputs\n",
        "        means = [None for _ in range(dec_inputs.shape[1])]\n",
        "        stds = [None for _ in range(dec_inputs.shape[1])]\n",
        "\n",
        "        enc_outputs, hidden = self.encoder(enc_inputs)\n",
        "        # outputs[0] = self.fc(output[:,-1,:])[:,None,:]\n",
        "\n",
        "        for t in range(dec_inputs.shape[1]):\n",
        "          # teacher_force = random.random() < teacher_force_probability\n",
        "\n",
        "          input_at_t = dec_inputs[:,t,:][:,np.newaxis,:]\n",
        "          mean, std, hidden = self.decoder(input_at_t, hidden, enc_outputs)\n",
        "\n",
        "          means[t] = mean\n",
        "          stds[t] = std\n",
        "\n",
        "        means = torch.stack(means, dim = 1)\n",
        "        means = torch.squeeze(means)\n",
        "\n",
        "        stds = torch.stack(stds, dim = 1)\n",
        "        stds = torch.squeeze(stds)\n",
        "\n",
        "        return means, stds, hidden\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._common_step(batch, batch_idx, self.teacher_force_probability, \"train\")\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self._common_step(batch, batch_idx, 0, \"val\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                  factor=0.3, patience=3,\n",
        "                                                  threshold=0.0001)\n",
        "\n",
        "        # return optimizer\n",
        "        return {\n",
        "           'optimizer': optimizer,\n",
        "           'lr_scheduler': scheduler,\n",
        "           'monitor': 'train_loss'\n",
        "       }\n",
        "\n",
        "    def _common_step(self, batch, batch_idx, teacher_force_probability, stage: str):\n",
        "        encoder_inputs, decoder_inputs, decoder_state_inputs, target = batch\n",
        "        encoder_inputs = encoder_inputs.to(device)\n",
        "        decoder_inputs = decoder_inputs.to(device)\n",
        "        decoder_state_inputs = decoder_state_inputs.to(device)\n",
        "\n",
        "        target = target[:,1:,:]\n",
        "        y = target.to(device)\n",
        "\n",
        "        # teacher_force_probability = round(10 * teacher_force_probability / max(1, self.current_epoch)) / 10\n",
        "        teacher_force_probability = max(0, teacher_force_probability - 0.025 * max(1, self.current_epoch) * teacher_force_probability)\n",
        "\n",
        "        means, stds, hidden = self(encoder_inputs, decoder_inputs,\n",
        "                             decoder_state_inputs, teacher_force_probability)\n",
        "\n",
        "        # loss = F.mse_loss(y_hat, y)\n",
        "        distr = torch.distributions.Normal(means, stds)\n",
        "        loss = -distr.log_prob(y).mean()\n",
        "        self.log(f\"{stage}_loss\", loss, on_step=True)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "tcG3Dp1rqfXJ"
      },
      "id": "tcG3Dp1rqfXJ",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderDistrib(nn.Module):\n",
        "    def __init__(self, dec_feature_size, dec_target_size,\n",
        "                 hidden_size, num_gru_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dec_feature_size = dec_feature_size\n",
        "        self.dec_target_size = dec_target_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_gru_layers = num_gru_layers\n",
        "\n",
        "        self.gru = nn.GRU(dec_feature_size, hidden_size, num_gru_layers,\n",
        "                          batch_first=True, dropout=dropout)\n",
        "        self.out = nn.Linear(hidden_size, 2*dec_target_size)\n",
        "\n",
        "    def forward(self, inputs, hidden, enc_outputs):\n",
        "\n",
        "        output, hidden = self.gru(inputs, hidden)\n",
        "        output = self.out(output)\n",
        "        mean, std = torch.tensor_split(output, 2, dim=-1)\n",
        "\n",
        "        std = F.relu(std) + 1e-6\n",
        "\n",
        "        return mean, std, hidden"
      ],
      "metadata": {
        "id": "DkejwFueA-Yd"
      },
      "id": "DkejwFueA-Yd",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JsZhiREUBLXd"
      },
      "id": "JsZhiREUBLXd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# r = model(dataset[0][0][np.newaxis,:,:], dataset[0][1][np.newaxis,:,:],)"
      ],
      "metadata": {
        "id": "PddAYdmBqpEk"
      },
      "id": "PddAYdmBqpEk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhGaX9D6180G"
      },
      "id": "lhGaX9D6180G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Модель Deep Factor"
      ],
      "metadata": {
        "id": "XoLIHjY22LIc"
      },
      "id": "XoLIHjY22LIc"
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, enc_feature_size, hidden_size, num_gru_layers, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.enc_feature_size = enc_feature_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_gru_layers = num_gru_layers\n",
        "\n",
        "    self.gru = nn.GRU(enc_feature_size, hidden_size, num_gru_layers,\n",
        "                      batch_first=True, dropout=dropout)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    output, hidden = self.gru(inputs)\n",
        "\n",
        "    return output, hidden"
      ],
      "metadata": {
        "id": "AFlbSEk2o-VS"
      },
      "id": "AFlbSEk2o-VS",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepFactor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, dec_target_size, hidden_size, nlayers, dropout):\n",
        "        super(DeepFactor, self).__init__()\n",
        "\n",
        "        self.dec_feature_size = input_size\n",
        "        self.dec_target_size = dec_target_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_gru_layers = nlayers\n",
        "\n",
        "        self.gru = nn.GRU(input_size, hidden_size, nlayers,\n",
        "                          bias=True, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, dec_target_size)\n",
        "\n",
        "    def forward(self, inputs, hidden, enc_outputs):\n",
        "        output, hidden = self.gru(inputs, hidden)\n",
        "        ht = F.relu(output)\n",
        "        gt = self.out(ht)\n",
        "        return gt, hidden"
      ],
      "metadata": {
        "id": "wMgvBI9c183X"
      },
      "id": "wMgvBI9c183X",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Noise(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, dec_target_size, hidden_size, nlayers, dropout):\n",
        "        super(Noise, self).__init__()\n",
        "\n",
        "        self.dec_feature_size = input_size\n",
        "        self.dec_target_size = dec_target_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_gru_layers = nlayers\n",
        "\n",
        "        self.gru = nn.GRU(input_size, hidden_size, nlayers,\n",
        "                           bias=True, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, dec_target_size)\n",
        "\n",
        "    def forward(self, inputs, hidden, enc_outputs):\n",
        "        output, hidden = self.gru(inputs, hidden)\n",
        "        ht = F.relu(output)\n",
        "        sigma_t = self.out(ht)\n",
        "        sigma_t = F.softplus(sigma_t)\n",
        "        return sigma_t, hidden"
      ],
      "metadata": {
        "id": "141Lk-p3aaxE"
      },
      "id": "141Lk-p3aaxE",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DFRNN(LightningModule):\n",
        "    def __init__(self, encoder, decoder_mu, decoder_sigma, lr: float = 1e-3, teacher_force_probability: int = 0):\n",
        "        super().__init__()\n",
        "        # self.save_hyperparameters(logger=False)\n",
        "        self.layers_size = {\n",
        "            'enc_feature_size': encoder.enc_feature_size,\n",
        "            'enc_hidden_size': encoder.hidden_size,\n",
        "            'enc_num_gru_layers': encoder.num_gru_layers,\n",
        "            'dec_feature_size': decoder_mu.dec_feature_size,\n",
        "            'dec_target_size': decoder_mu.dec_target_size,\n",
        "            'dec_hidden_size': decoder_mu.hidden_size,\n",
        "            'dec.num_gru_layers': decoder_mu.num_gru_layers\n",
        "            }\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder_mu = decoder_mu\n",
        "        self.decoder_sigma = decoder_sigma\n",
        "\n",
        "        self.lr = lr\n",
        "        self.teacher_force_probability = teacher_force_probability\n",
        "\n",
        "\n",
        "    def forward(self, enc_inputs, dec_inputs, dec_state_inputs=None,\n",
        "                teacher_force_probability=0):\n",
        "\n",
        "        # Store outputs\n",
        "        means = [None for _ in range(dec_inputs.shape[1])]\n",
        "        stds = [None for _ in range(dec_inputs.shape[1])]\n",
        "\n",
        "        enc_outputs, hidden = self.encoder(enc_inputs)\n",
        "        # outputs[0] = self.fc(output[:,-1,:])[:,None,:]\n",
        "\n",
        "\n",
        "        means, mean_headen = self.decoder_mu(dec_inputs, hidden, enc_outputs)\n",
        "        stds, std_headen  = self.decoder_sigma(dec_inputs, hidden, enc_outputs)\n",
        "\n",
        "        # for t in range(dec_inputs.shape[1]):\n",
        "        #   # teacher_force = random.random() < teacher_force_probability\n",
        "\n",
        "        #   input_at_t = dec_inputs[:,t,:][:,np.newaxis,:]\n",
        "        #   mean, std, hidden = self.decoder(input_at_t, hidden, enc_outputs)\n",
        "\n",
        "        #   means[t] = mean\n",
        "        #   stds[t] = std\n",
        "\n",
        "        # means = torch.stack(means, dim = 1)\n",
        "        # means = torch.squeeze(means)\n",
        "\n",
        "        # stds = torch.stack(stds, dim = 1)\n",
        "        # stds = torch.squeeze(stds)\n",
        "\n",
        "        return means, stds, (mean_headen, std_headen)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # lr = self.trainer.lr_scheduler_configs[0].scheduler.get_last_lr()[0]\n",
        "        # self.log('learning_rate', lr, prog_bar=True)\n",
        "        return self._common_step(batch, batch_idx, self.teacher_force_probability, \"train\")\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self._common_step(batch, batch_idx, 0, \"val\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                  factor=0.5, patience=1,\n",
        "                                                  threshold=1e-4)\n",
        "\n",
        "        # return optimizer\n",
        "        return {\n",
        "           'optimizer': optimizer,\n",
        "           'lr_scheduler': scheduler,\n",
        "           'monitor': 'train_loss'\n",
        "       }\n",
        "\n",
        "    def _common_step(self, batch, batch_idx, teacher_force_probability, stage: str):\n",
        "        encoder_inputs, decoder_inputs, decoder_state_inputs, target = batch\n",
        "        encoder_inputs = encoder_inputs.to(device)\n",
        "        decoder_inputs = decoder_inputs.to(device)\n",
        "        decoder_state_inputs = decoder_state_inputs.to(device)\n",
        "\n",
        "        target = target[:,1:,:]\n",
        "        y = target.to(device)\n",
        "\n",
        "        # teacher_force_probability = round(10 * teacher_force_probability / max(1, self.current_epoch)) / 10\n",
        "        teacher_force_probability = max(0, teacher_force_probability - 0.025 * max(1, self.current_epoch) * teacher_force_probability)\n",
        "\n",
        "        means, stds, hidden = self(encoder_inputs, decoder_inputs,\n",
        "                             decoder_state_inputs, teacher_force_probability)\n",
        "\n",
        "        # loss = F.mse_loss(y_hat, y)\n",
        "        distr = torch.distributions.Normal(means, stds)\n",
        "        loss = -distr.log_prob(y).mean()\n",
        "        self.log(f\"{stage}_loss\", loss, on_step=True)\n",
        "\n",
        "        self.log(f\"{stage}_mse\", F.mse_loss(means, y), on_step=True)\n",
        "        self.log(f\"{stage}_mae\", F.l1_loss(means, y), on_step=True)\n",
        "        self.log(f\"{stage}_mean_std\", stds.mean(), on_step=True)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "zLwvvMRbd_QL"
      },
      "id": "zLwvvMRbd_QL",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfekipCa186g"
      },
      "id": "SfekipCa186g",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch = next(iter(train_loader))\n",
        "# encoder_inputs, decoder_inputs, decoder_state_inputs, target = batch\n",
        "\n",
        "# encoder = Encoder(input_features_encoder, 1024, 2, dropout = 0)\n",
        "# mu_model = DeepFactor(input_features_decoder, output_features, 1024, 2, dropout = 0)\n",
        "# sigma_model = Noise(input_features_decoder, output_features, 1024, 2, dropout = 0)\n",
        "\n",
        "# model = DFRNN(encoder, mu_model, sigma_model)\n",
        "# result = model(encoder_inputs, decoder_inputs)"
      ],
      "metadata": {
        "id": "t0-sR1t2T0cG"
      },
      "id": "t0-sR1t2T0cG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GnUgszLWZta"
      },
      "id": "4GnUgszLWZta",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "80PcF1FCXCyx"
      },
      "id": "80PcF1FCXCyx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "VjfB7yRIbv7k",
      "metadata": {
        "id": "VjfB7yRIbv7k"
      },
      "source": [
        "## Модель LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "fto0B6gz1LZ4",
      "metadata": {
        "id": "fto0B6gz1LZ4"
      },
      "outputs": [],
      "source": [
        "class GTDLSTM(LightningModule):\n",
        "    def __init__(self, num_input, hidden_units, num_output,\n",
        "                 num_layers=1, lr: float = 1e-3, teacher_force_probability: int = 0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers_size = {\n",
        "            'input_features': num_input,\n",
        "            'output_features': num_output,\n",
        "            'hidden_dim': hidden_units,\n",
        "            'hidden_num': num_layers}\n",
        "\n",
        "        self.num_input = num_input  # this is the number of features\n",
        "        self.hidden_units = hidden_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lr = lr\n",
        "        self.teacher_force_probability = teacher_force_probability\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=num_input,\n",
        "            hidden_size=hidden_units,\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_units, num_output)\n",
        "\n",
        "    def forward(self, enc_inputs, dec_inputs, dec_state_inputs=None,\n",
        "                teacher_force_probability=0):\n",
        "\n",
        "\n",
        "        # Store outputs\n",
        "        outputs = [None for _ in range(dec_inputs.shape[1]+1)]\n",
        "\n",
        "        output, hidden = self.lstm(enc_inputs)\n",
        "        outputs[0] = self.fc(output[:,-1,:])[:,None,:]\n",
        "\n",
        "        for t in range(dec_inputs.shape[1]):\n",
        "          teacher_force = random.random() < teacher_force_probability\n",
        "\n",
        "          input_at_t = torch.cat(\n",
        "              (dec_inputs[:,t,:][:,np.newaxis,:], dec_state_inputs[:,t,:][:,np.newaxis,:]), 2) if teacher_force else torch.cat(\n",
        "                  (dec_inputs[:,t,:][:,np.newaxis,:], outputs[t]), 2)\n",
        "\n",
        "          output, hidden = self.lstm(input_at_t, hidden)\n",
        "\n",
        "          outputs[t+1] = self.fc(output)\n",
        "\n",
        "        outputs = torch.stack(outputs, dim = 1)\n",
        "        outputs = torch.squeeze(outputs)\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._common_step(batch, batch_idx, self.teacher_force_probability, \"train\")\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self._common_step(batch, batch_idx, 0, \"val\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                  factor=0.3, patience=3,\n",
        "                                                  threshold=0.0001)\n",
        "\n",
        "        # return optimizer\n",
        "        return {\n",
        "           'optimizer': optimizer,\n",
        "           'lr_scheduler': scheduler,\n",
        "           'monitor': 'train_loss'\n",
        "       }\n",
        "\n",
        "    def _common_step(self, batch, batch_idx, teacher_force_probability, stage: str):\n",
        "        encoder_inputs, decoder_inputs, decoder_state_inputs, target = batch\n",
        "        encoder_inputs = encoder_inputs.to(device)\n",
        "        decoder_inputs = decoder_inputs.to(device)\n",
        "        decoder_state_inputs = decoder_state_inputs.to(device)\n",
        "\n",
        "        y = target.to(device)\n",
        "\n",
        "        # teacher_force_probability = round(10 * teacher_force_probability / max(1, self.current_epoch)) / 10\n",
        "        teacher_force_probability = max(0, teacher_force_probability - 0.025 * max(1, self.current_epoch) * teacher_force_probability)\n",
        "\n",
        "        y_hat, hidden = self(encoder_inputs, decoder_inputs,\n",
        "                             decoder_state_inputs, teacher_force_probability)\n",
        "\n",
        "        # loss = nn.L1Loss(y_hat, y)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        self.log(f\"{stage}_loss\", loss, on_step=True)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Эксперименты"
      ],
      "metadata": {
        "id": "2Op09KqB2Gpz"
      },
      "id": "2Op09KqB2Gpz"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mR5ipWDyUs9j"
      },
      "id": "mR5ipWDyUs9j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "IifuXlBxih1F",
      "metadata": {
        "id": "IifuXlBxih1F"
      },
      "outputs": [],
      "source": [
        "params_info = {'input': input_data,\n",
        "               'output': output_data}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "fXDK5lC2iprO",
      "metadata": {
        "id": "fXDK5lC2iprO"
      },
      "outputs": [],
      "source": [
        "encoder_length = 60\n",
        "decoder_length = 600\n",
        "\n",
        "# input_features = len(input_data)+len(output_data)\n",
        "input_features_encoder = len(input_data)+len(output_data)\n",
        "input_features_decoder = len(input_data)\n",
        "output_features = len(output_data)\n",
        "hidden_dim = 1024\n",
        "hidden_num = 2\n",
        "learning_rate = 1e-3\n",
        "teacher_force_probability = 0\n",
        "encoder_shufle = 0.2\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "checkpoints_dir = './runs'\n",
        "\n",
        "data_step = 120\n",
        "\n",
        "encoder = Encoder(\n",
        "    enc_feature_size = input_features_encoder,\n",
        "    hidden_size = hidden_dim,\n",
        "    num_gru_layers = hidden_num,\n",
        "    dropout = 0\n",
        ")\n",
        "\n",
        "# decoder = DecoderVanilla(\n",
        "#     dec_feature_size = input_features_decoder,\n",
        "#     dec_target_size = output_features,\n",
        "#     hidden_size = hidden_dim,\n",
        "#     num_gru_layers = hidden_num,\n",
        "#     dropout = 0\n",
        "# )\n",
        "\n",
        "# decoder = DecoderDistrib(\n",
        "#     dec_feature_size = input_features_decoder,\n",
        "#     dec_target_size = output_features,\n",
        "#     hidden_size = hidden_dim,\n",
        "#     num_gru_layers = hidden_num,\n",
        "#     dropout = 0\n",
        "# )\n",
        "\n",
        "# mu_decoder = DeepFactor(\n",
        "#     input_features_decoder,\n",
        "#     output_features,\n",
        "#     hidden_dim,\n",
        "#     hidden_num,\n",
        "#     dropout = 0)\n",
        "\n",
        "# sigma_decoder = Noise(\n",
        "#     input_features_decoder,\n",
        "#     output_features,\n",
        "#     hidden_dim,\n",
        "#     hidden_num,\n",
        "#     dropout = 0)\n",
        "\n",
        "# model = DFRNN(encoder, mu_decoder, sigma_decoder, learning_rate)\n",
        "\n",
        "decoder = DecoderWithAttention(\n",
        "    dec_feature_size = input_features_decoder,\n",
        "    dec_target_size = output_features,\n",
        "    hidden_size = hidden_dim,\n",
        "    num_gru_layers = hidden_num,\n",
        "    dropout = 0\n",
        ")\n",
        "\n",
        "model = Seq2Seq_onlyx_decoder(\n",
        "    encoder = encoder,\n",
        "    decoder = decoder,\n",
        "    lr = learning_rate,\n",
        "    teacher_force_probability = teacher_force_probability,\n",
        "    encoder_shufle=encoder_shufle\n",
        ")\n",
        "\n",
        "# model = Seq2SeqDistrib(\n",
        "#     encoder = encoder,\n",
        "#     decoder = decoder,\n",
        "#     lr = learning_rate,\n",
        "#     teacher_force_probability = teacher_force_probability\n",
        "# )\n",
        "\n",
        "# model = Seq2Seq(\n",
        "#     encoder = encoder,\n",
        "#     decoder = decoder,\n",
        "#     lr = learning_rate,\n",
        "#     teacher_force_probability = teacher_force_probability\n",
        "# )\n",
        "\n",
        "# model = GTDLSTM(\n",
        "#     num_input = input_features,\n",
        "#     hidden_units = hidden_dim,\n",
        "#     num_output=output_features,\n",
        "#     num_layers=hidden_num,\n",
        "#     lr=learning_rate,\n",
        "#     teacher_force_probability = teacher_force_probability)\n",
        "\n",
        "\n",
        "\n",
        "model_layers = {'layers': model.layers_size}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "uzDdvAWMip0j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzDdvAWMip0j",
        "outputId": "6ad50a8b-a31a-498e-d4d2-f93164ee2230"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6397"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "dataset = SequenceDatasetForRNN(\n",
        "            parquetFileList,\n",
        "            input_data,\n",
        "            output_data,\n",
        "            encoder_length=encoder_length,\n",
        "            decoder_length=decoder_length,\n",
        "            scaler_input=scaler_input,\n",
        "            scaler_output=scaler_output,\n",
        "            shift = 0,\n",
        "            step = data_step\n",
        "        )\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7jxbrXKc2U4O",
      "metadata": {
        "id": "7jxbrXKc2U4O"
      },
      "outputs": [],
      "source": [
        "# for d in dataset[1]:\n",
        "#   print(d.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "cv2etp022Emp",
      "metadata": {
        "id": "cv2etp022Emp"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JoPJq2jXqOlf",
      "metadata": {
        "id": "JoPJq2jXqOlf"
      },
      "outputs": [],
      "source": [
        "# for batch in train_loader:\n",
        "\n",
        "#   encoder_inputs, decoder_inputs, decoder_state_inputs, target = batch\n",
        "\n",
        "#   print(\"encoder_inputs.shape: \", encoder_inputs.shape)\n",
        "#   print(\"decoder_inputs.shape: \", decoder_inputs.shape)\n",
        "#   print(\"decoder_state_inputs.shape: \", decoder_state_inputs.shape)\n",
        "\n",
        "#   input_t = torch.cat((decoder_inputs[:,0,:][:,np.newaxis,:], decoder_state_inputs[:,0,:][:,np.newaxis,:]), axis=2)\n",
        "#   print(\"input_t.shape: \", input_t.shape)\n",
        "\n",
        "#   model.eval()\n",
        "#   with torch.no_grad():\n",
        "#     outputs, hidden = model(encoder_inputs, decoder_inputs, decoder_state_inputs)\n",
        "#   # model.training_step(batch, 0)\n",
        "\n",
        "#   print(\"outputs.shape: \", outputs.shape)\n",
        "#   print(\"target.shape: \", target.shape)\n",
        "#   print(\"hidden.shape: \", hidden.shape)\n",
        "\n",
        "#   break"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "puTAL-511K3g"
      },
      "id": "puTAL-511K3g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = mlflow.pytorch.load_checkpoint(DFRNN, \"90e11edf6a1e48c899c06fefe5f11395\", epoch=94)"
      ],
      "metadata": {
        "id": "TRVhR5ixz2FT"
      },
      "id": "TRVhR5ixz2FT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mlflow.pytorch.load_checkpoint?"
      ],
      "metadata": {
        "id": "C6kGUvHS_FfP"
      },
      "id": "C6kGUvHS_FfP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mlflow.pyfunc.load_model(\"/content/drive/MyDrive/RNN-models/latest_checkpoint.pth\")"
      ],
      "metadata": {
        "id": "QPImb1VW1fkt"
      },
      "id": "QPImb1VW1fkt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mlflow.pyfunc.load_model?"
      ],
      "metadata": {
        "id": "pj2cvm7w6FjY"
      },
      "id": "pj2cvm7w6FjY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint = torch.load(\"/content/drive/MyDrive/RNN-models/latest_checkpoint.pth\", weights_only=True)\n",
        "# model.load_state_dict(checkpoint['state_dict'])"
      ],
      "metadata": {
        "id": "GuSR2WyM8AKE"
      },
      "id": "GuSR2WyM8AKE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qIeyfQ6sI5WP"
      },
      "id": "qIeyfQ6sI5WP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9TgE6BSH79L"
      },
      "id": "Y9TgE6BSH79L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8RlCD2QIVp7"
      },
      "id": "f8RlCD2QIVp7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.decoder_mu.state_dict()"
      ],
      "metadata": {
        "id": "xhr_4GNkIP8_"
      },
      "id": "xhr_4GNkIP8_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.decoder_mu.state_dict()"
      ],
      "metadata": {
        "id": "2VY2hUKz8TE5"
      },
      "id": "2VY2hUKz8TE5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "of1EFxYsC3Mc"
      },
      "id": "of1EFxYsC3Mc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ckpt_url = \"mlflow-artifacts:/deab5565b6d248838aa2741673be86a0/90e11edf6a1e48c899c06fefe5f11395/artifacts/sample-epoch=94-train_loss=-5.00-val_loss=-5.07/sample-epoch=94-train_loss=-5.00-val_loss=-5.07.ckpt\""
      ],
      "metadata": {
        "id": "H4n9KE3VC3Pc"
      },
      "id": "H4n9KE3VC3Pc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mlflow.artifacts.download_artifacts(ckpt_url)"
      ],
      "metadata": {
        "id": "XISO1uJpC3Se"
      },
      "id": "XISO1uJpC3Se",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DFRNN.load_from_checkpoint(\"/tmp/tmp0669upw8/sample-epoch=94-train_loss=-5.00-val_loss=-5.07.ckpt\")"
      ],
      "metadata": {
        "id": "4F_Y7EhwBCm8"
      },
      "id": "4F_Y7EhwBCm8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(mlflow.artifacts.download_artifacts(logged_info)) as f:\n",
        "# #     model_info = json.load(f)"
      ],
      "metadata": {
        "id": "90mg2ZDL8yE4"
      },
      "id": "90mg2ZDL8yE4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmw-W5VI1nx1"
      },
      "id": "pmw-W5VI1nx1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "MdvM6085ip8t",
      "metadata": {
        "id": "MdvM6085ip8t"
      },
      "outputs": [],
      "source": [
        "EXP_NAME = \"Training Seq2Seq with phys\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "QpG4F4zMkEpm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpG4F4zMkEpm",
        "outputId": "5feddb5a-a9ec-42d4-d9a2-5685b4b05a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /pranamodeling/gas-prop-net.mlflow/api/2.0/mlflow/experiments/get-by-name?experiment_name=Training+Seq2Seq+with+phys\n",
            "2025/07/04 07:38:22 INFO mlflow.tracking.fluent: Experiment with name 'Training Seq2Seq with phys' does not exist. Creating a new experiment.\n",
            "2025/07/04 07:38:23 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.6.0, but the installed version is 2.6.0+cu124. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ActiveRun: >"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "mlflow.set_experiment(EXP_NAME)\n",
        "mlflow.pytorch.autolog()\n",
        "mlflow.start_run(run_name=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "xVtXgntckEuS",
      "metadata": {
        "id": "xVtXgntckEuS"
      },
      "outputs": [],
      "source": [
        "mlf_logger = MLFlowLogger(\n",
        "    experiment_name=mlflow.get_experiment(mlflow.active_run().info.experiment_id).name,\n",
        "    tracking_uri=mlflow.get_tracking_uri(),\n",
        "    run_id=mlflow.active_run().info.run_id,\n",
        "    log_model=\"all\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "bwen2eckkUNB",
      "metadata": {
        "id": "bwen2eckkUNB"
      },
      "outputs": [],
      "source": [
        "e_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0.0001,\n",
        "    patience=6,\n",
        "    verbose=False,\n",
        "    mode=\"min\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "hFgBm040kUQ-",
      "metadata": {
        "id": "hFgBm040kUQ-"
      },
      "outputs": [],
      "source": [
        "# TRAIN\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=checkpoints_dir,\n",
        "    monitor='train_loss',\n",
        "    filename=\"sample-{epoch:02d}-{train_loss:.2f}-{val_loss:.2f}\",\n",
        "    save_top_k=5,\n",
        "    save_weights_only=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step')"
      ],
      "metadata": {
        "id": "U2dBi8fvdvPe"
      },
      "id": "U2dBi8fvdvPe",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "e5CGHn1vkYk6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5CGHn1vkYk6",
        "outputId": "e1ee30b5-c96e-4c73-a290-4acbf09f1a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    # auto_scale_batch_size=True,\n",
        "    # auto_lr_find=True,\n",
        "    devices=\"auto\",\n",
        "    accelerator=\"auto\",\n",
        "    log_every_n_steps=5,\n",
        "    max_epochs=40,\n",
        "    min_epochs=10,\n",
        "    enable_checkpointing=True,\n",
        "    default_root_dir=checkpoints_dir,\n",
        "    logger=mlf_logger,\n",
        "    callbacks=[e_stop, checkpoint_callback, lr_monitor]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1qFB01WOkYr-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "3f8b60dbd1344375949944ceb97c9ba6",
            "b3b475138e174bb38d57b5ec57eac548",
            "b284b99d34cc4ec2aaae6889191f3f7e",
            "83e819c5931548ad9cd732ace95b3a83",
            "522699c00fca4c19a960aab008e9465b",
            "7a3c76976e9f4331b9ee2667f778cef3",
            "8ef8ed65218a42eb855496abefbae9df",
            "9821068505f54b32ad14f0e3a00bef60",
            "550ce55299394f5aa8a34759b9d19b76",
            "ad0666be19ae4f7cb50030a13fb33a9f",
            "f0405c38184c4e0ca79b04d88267c531",
            "399a69a50340447aad75bafeb7820a19",
            "fed53c7cfe02408793201bf035753142",
            "295195a8000447fbbe169caf665be7fc",
            "c292656bb1854c1c8ab8dae2b6ed8d57",
            "f39d948a16494d7baace7a446ece711e",
            "8c99e817d89646f69d27c38bd2c7d138",
            "4b8ce11a5f384a4783701065a281db4e",
            "b3306121696449d9bade84b5eb5a6dbd",
            "e2ed9763a13841aa9dd4e9a6cdec4107",
            "550e100b82be4a7bbb9677f8ee31a21e",
            "0dfc4a5d7abe45919c0cd648c76aeb22"
          ]
        },
        "id": "1qFB01WOkYr-",
        "outputId": "d6225868-4bda-470f-f766-0d2e888aaf08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/04 07:38:41 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/mlflow/pytorch/_lightning_autolog.py:465: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.9.0 and 2.5.1 and may not succeed with packages outside this range.\"\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /pranamodeling/gas-prop-net.mlflow/api/2.0/mlflow/runs/log-batch\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name    | Type                 | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | encoder | Encoder              | 9.5 M  | train\n",
            "1 | decoder | DecoderWithAttention | 14.7 M | train\n",
            "---------------------------------------------------------\n",
            "24.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "24.2 M    Total params\n",
            "96.952    Total estimated model params size (MB)\n",
            "8         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f8b60dbd1344375949944ceb97c9ba6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "399a69a50340447aad75bafeb7820a19"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.fit(model, train_loader, test_loader)\n",
        "\n",
        "mlf_logger.experiment.log_artifact(run_id=mlf_logger.run_id,\n",
        "                                   local_path=checkpoint_callback.best_model_path)  # , infer_signature())\n",
        "\n",
        "mlf_logger.experiment.log_dict(run_id=mlf_logger.run_id,\n",
        "                               dictionary={\n",
        "                                   \"data_step\": data_step,\n",
        "                                   \"encoder_length\": encoder_length,\n",
        "                                   \"decoder_length\": decoder_length,\n",
        "                                   \"batch_size\": batch_size,\n",
        "                                   \"teacher_force_probability\": teacher_force_probability,\n",
        "                                   **params_info,\n",
        "                                   **prep_input_info,\n",
        "                                   **prep_output_info,\n",
        "                                   **model_layers},\n",
        "                               artifact_file='info.json')\n",
        "\n",
        "x_ex = {\n",
        "    \"enc_inputs\":train_dataset.__getitem__(0)[0].detach().numpy()[None, :],\n",
        "    \"dec_inputs\": train_dataset.__getitem__(0)[1].detach().numpy()[None, :]\n",
        "    }\n",
        "y_ex = train_dataset.__getitem__(0)[-1].detach().numpy()[None, :]\n",
        "signature = infer_signature(x_ex, y_ex)\n",
        "\n",
        "mlflow.pytorch.log_model(model, 'mdllol', signature=signature)\n",
        "\n",
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H4a5CSoAkUUx",
      "metadata": {
        "id": "H4a5CSoAkUUx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55p2I9S6kEzb",
      "metadata": {
        "id": "55p2I9S6kEzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312ae54c-dc3e-4b50-b43f-dfcdf09f0c5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏃 View run chill-cow-760 at: https://dagshub.com/pranamodeling/seq2seq-gtd-6rm.mlflow/#/experiments/3/runs/415dd70f41624e4aa72cf23e3fd68698\n",
            "🧪 View experiment at: https://dagshub.com/pranamodeling/seq2seq-gtd-6rm.mlflow/#/experiments/3\n"
          ]
        }
      ],
      "source": [
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hiw9WL4zqtzA",
      "metadata": {
        "id": "Hiw9WL4zqtzA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "571jb-ASqt2s",
      "metadata": {
        "id": "571jb-ASqt2s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qvu32j67qt6d",
      "metadata": {
        "id": "qvu32j67qt6d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7uFv_Zs2Q-b",
      "metadata": {
        "id": "e7uFv_Zs2Q-b"
      },
      "outputs": [],
      "source": [
        "x_ex = list(map(lambda x: x.detach().numpy(), train_dataset.__getitem__(0)[0:2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ez0Z20c2262z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez0Z20c2262z",
        "outputId": "200c9bc4-4ab4-411d-a01e-ec371c9e5f20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1, 300, 8)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_ex[1][None, None, :].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6go5vUAY266j",
      "metadata": {
        "id": "6go5vUAY266j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o-1Yc7JN26-S",
      "metadata": {
        "id": "o-1Yc7JN26-S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-FyYOWNG2RC6",
      "metadata": {
        "id": "-FyYOWNG2RC6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f413f4-8f34-446f-b944-f66103b0a30c",
      "metadata": {
        "id": "11f413f4-8f34-446f-b944-f66103b0a30c"
      },
      "outputs": [],
      "source": [
        "# функция для обучения модели\n",
        "\n",
        "def train_model(filenames, model, loss_function, optimizer, model_filename, batch_size=512, teacher_force_probability=0):\n",
        "\n",
        "    random.shuffle(filenames)\n",
        "    file_loss = 0\n",
        "\n",
        "    for file in tqdm(filenames):\n",
        "        dataset = SequenceDataset(\n",
        "            file,\n",
        "            input_data,\n",
        "            output_data,\n",
        "            encoder_length=encoder_length,\n",
        "            decoder_length=decoder_length,\n",
        "            scaler_input=scaler_input,\n",
        "            scaler_output=scaler_output,\n",
        "            shift = 0\n",
        "        )\n",
        "\n",
        "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        num_batches = len(data_loader)\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        for encoder_inputs, decoder_inputs, decoder_state_inputs, target in data_loader:\n",
        "            encoder_inputs = encoder_inputs.to(device)\n",
        "            decoder_inputs = decoder_inputs.to(device)\n",
        "            decoder_state_inputs = decoder_state_inputs.to(device)\n",
        "\n",
        "            y = target.to(device)\n",
        "\n",
        "            output, hidden = model(encoder_inputs, decoder_inputs,\n",
        "                                   decoder_state_inputs, teacher_force_probability)\n",
        "\n",
        "            # output, hidden = model(encoder_inputs, decoder_inputs, y, teacher_force_probability=teacher_force_probability)\n",
        "            loss = loss_function(output, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        torch.save(model.state_dict(), f'/content/drive/MyDrive/RNN-models/{model_filename}')\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        # print(f\"Train loss: {avg_loss}\")\n",
        "\n",
        "        file_loss += avg_loss\n",
        "    epoch_loss = file_loss / len(filenames)\n",
        "    return epoch_loss\n",
        "\n",
        "# функция для тестирования модели\n",
        "\n",
        "def test_model(filenames, model, loss_function, batch_size=512):\n",
        "\n",
        "    file_loss = 0\n",
        "\n",
        "    for file in tqdm(filenames):\n",
        "        dataset = SequenceDataset(\n",
        "            file,\n",
        "            input_data,\n",
        "            output_data,\n",
        "            encoder_length=encoder_length,\n",
        "            decoder_length=decoder_length,\n",
        "            scaler_input=scaler_input,\n",
        "            scaler_output=scaler_output\n",
        "        )\n",
        "\n",
        "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        num_batches = len(data_loader)\n",
        "        total_loss = 0\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for encoder_inputs, decoder_inputs, decoder_state_inputs, target in data_loader:\n",
        "                encoder_inputs = encoder_inputs.to(device)\n",
        "                decoder_inputs = decoder_inputs.to(device)\n",
        "                decoder_state_inputs = decoder_state_inputs.to(device)\n",
        "\n",
        "                y = target.to(device)\n",
        "\n",
        "                output, hidden = model(encoder_inputs,\n",
        "                                       decoder_inputs,\n",
        "                                       decoder_state_inputs,\n",
        "                                       teacher_force_probability = 0)\n",
        "                total_loss += loss_function(output, y).item()\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        # print(f\"Test loss: {avg_loss}\")\n",
        "\n",
        "        file_loss += avg_loss\n",
        "    epoch_loss = file_loss / len(filenames)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k45bQksLWy8V",
      "metadata": {
        "id": "k45bQksLWy8V"
      },
      "outputs": [],
      "source": [
        "# num_input, hidden_units, num_output, num_layers=1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aFXg9a27W0Jw",
      "metadata": {
        "id": "aFXg9a27W0Jw"
      },
      "source": [
        "### Обучение LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BkBFJI3VWzCe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkBFJI3VWzCe",
        "outputId": "a704dde3-71bf-4ae2-8698-038b1e2ccfb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "GTDLSTM                                  --\n",
              "├─LSTM: 1-1                              1,091,584\n",
              "├─Linear: 1-2                            5,643\n",
              "=================================================================\n",
              "Total params: 1,097,227\n",
              "Trainable params: 1,097,227\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder_length = 60\n",
        "decoder_length = 300\n",
        "hidden_size = 512\n",
        "num_lstm_layers = 1\n",
        "learning_rate = 0.01\n",
        "# teacher_force_probability = 0.5\n",
        "batch_size = 512\n",
        "num_epoch = 50\n",
        "\n",
        "current_dateTime = \"{:%d%m%y}\".format(datetime.now())\n",
        "model_filename = f\"lstm_{current_dateTime}.pt\"\n",
        "\n",
        "model = GTDLSTM(\n",
        "    num_input = len(input_data)+len(output_data),\n",
        "    hidden_units = hidden_size,\n",
        "    num_output=len(output_data),\n",
        "    num_layers=1)\n",
        "\n",
        "model.to(device)\n",
        "loss_function = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3,\n",
        "                                           patience=3, threshold=0.0001)\n",
        "\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BVXvry3xYQUx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "BVXvry3xYQUx",
        "outputId": "82e8863d-a51e-4ec5-f846-04060861c36b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4\n",
            "---------\n",
            "Train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/56 [00:08<?, ?it/s]\n",
            "2024/11/14 09:07:43 INFO mlflow.tracking._tracking_service.client: 🏃 View run kindly-lynx-60 at: https://dagshub.com/pranamodeling/seq2seq-gtd-6rm.mlflow/#/experiments/0/runs/db75b7f39b874d9f9e258de104ebabdf.\n",
            "2024/11/14 09:07:43 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/pranamodeling/seq2seq-gtd-6rm.mlflow/#/experiments/0.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-da429849ebe9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mteacher_force_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_force_probability_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix_epoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       train_loss = train_model(train_files, model,\n\u001b[0m\u001b[1;32m     43\u001b[0m                               \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-7f4157bf2968>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(filenames, model, loss_function, optimizer, model_filename, batch_size, teacher_force_probability)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'/content/drive/MyDrive/RNN-models/{model_filename}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "with mlflow.start_run() as run:\n",
        "\n",
        "  mlflow.log_param(\"encoder_length\", str(encoder_length))\n",
        "  mlflow.log_param(\"decoder_length\", decoder_length)\n",
        "  mlflow.log_param(\"hidden_size\", hidden_size)\n",
        "  mlflow.log_param(\"num_lstm_layers\", num_lstm_layers)\n",
        "  # mlflow.log_param(\"dropout\", dropout)\n",
        "  mlflow.log_param(\"learning_rate\", learning_rate)\n",
        "  mlflow.log_param(\"summary\", summary(model))\n",
        "  # mlflow.log_param(\"teacher_force_probability\", teacher_force_probability)\n",
        "  mlflow.log_param(\"batch_size\", batch_size)\n",
        "\n",
        "  teacher_force_probability_list = [max(i/num_epoch, 0) for i in range(num_epoch, round(-num_epoch*0.3), -1)]\n",
        "\n",
        "  y_loss = {}  # loss history\n",
        "  y_loss['train'] = []\n",
        "  y_loss['val'] = []\n",
        "  lr = []\n",
        "\n",
        "\n",
        "  x_epoch = []\n",
        "  fig = plt.figure()\n",
        "\n",
        "\n",
        "  def draw_curve(current_epoch):\n",
        "      x_epoch.append(current_epoch)\n",
        "      plt.plot(x_epoch, y_loss['train'], 'bo-', label='train')\n",
        "      plt.plot(x_epoch, y_loss['val'], 'ro-', label='val')\n",
        "      # ax1.plot(x_epoch, y_err['train'], 'bo-', label='train')\n",
        "      # ax1.plot(x_epoch, y_err['val'], 'ro-', label='val')\n",
        "      if current_epoch == 0:\n",
        "          plt.legend()\n",
        "          # ax1.legend()\n",
        "      # fig.savefig(os.path.join('./lossGraphs', 'train.jpg'))\n",
        "\n",
        "\n",
        "  for ix_epoch in range(num_epoch):\n",
        "      print(f\"Epoch {ix_epoch+1}\\n---------\")\n",
        "      print(\"Train\")\n",
        "\n",
        "      teacher_force_probability = teacher_force_probability_list[ix_epoch]\n",
        "      train_loss = train_model(train_files, model,\n",
        "                              loss_function,\n",
        "                              optimizer=optimizer,\n",
        "                              model_filename=model_filename,\n",
        "                              batch_size=batch_size,\n",
        "                              teacher_force_probability=teacher_force_probability)\n",
        "      print(\"Test\")\n",
        "      test_loss = test_model(\n",
        "          test_files, model, loss_function, batch_size=batch_size)\n",
        "\n",
        "      mlflow.log_metric(\"train_loss\", train_loss, step=ix_epoch)\n",
        "      mlflow.log_metric(\"test_loss\", test_loss, step=ix_epoch)\n",
        "\n",
        "      y_loss['train'].append(train_loss)\n",
        "      y_loss['val'].append(test_loss)\n",
        "\n",
        "      clear_output(wait=True)\n",
        "      draw_curve(ix_epoch)\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "      lr.append(scheduler.get_last_lr())\n",
        "      scheduler.step(train_loss)\n",
        "\n",
        "  mlflow.pytorch.log_model(model, \"model\")\n",
        "\n",
        "\n",
        "  model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
        "  loaded_model = mlflow.pytorch.load_model(model_uri)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lZ0Bj8-EZz6n",
      "metadata": {
        "id": "lZ0Bj8-EZz6n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XvVTmDVtZz9p",
      "metadata": {
        "id": "XvVTmDVtZz9p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K1nYm0uTZ0Cu",
      "metadata": {
        "id": "K1nYm0uTZ0Cu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "FW7Kz3Y4W7n3",
      "metadata": {
        "id": "FW7Kz3Y4W7n3"
      },
      "source": [
        "### Обучение Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741dab8f-8465-4c9d-b4f9-b61ae6f29a78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "741dab8f-8465-4c9d-b4f9-b61ae6f29a78",
        "outputId": "19215e29-ecc7-4029-955f-710099962097"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "Seq2Seq                                  --\n",
              "├─Encoder: 1-1                           --\n",
              "│    └─GRU: 2-1                          818,688\n",
              "├─Decoder: 1-2                           --\n",
              "│    └─GRU: 2-2                          801,792\n",
              "│    └─Linear: 2-3                       5,643\n",
              "=================================================================\n",
              "Total params: 1,626,123\n",
              "Trainable params: 1,626,123\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder_length = 600\n",
        "decoder_length = 300\n",
        "hidden_size = 512\n",
        "num_gru_layers = 1\n",
        "dropout = 0.\n",
        "learning_rate = 5e-4\n",
        "teacher_force_probability = 0.5\n",
        "batch_size = 1024\n",
        "num_epoch = 10\n",
        "\n",
        "current_dateTime = \"{:%d%m%y}\".format(datetime.now())\n",
        "model_filename = f\"seq2seq_{current_dateTime}.pt\"\n",
        "\n",
        "encoder = Encoder(\n",
        "    enc_feature_size = len(input_data)+len(output_data),\n",
        "    hidden_size = hidden_size,\n",
        "    num_gru_layers = num_gru_layers,\n",
        "    dropout =  dropout\n",
        ")\n",
        "\n",
        "# decoder = DecoderWithTeacherForce(\n",
        "#     dec_feature_size = len(input_data)+len(output_data),\n",
        "#     dec_target_size = len(output_data),\n",
        "#     hidden_size = hidden_size,\n",
        "#     num_gru_layers = num_gru_layers,\n",
        "#     dropout =  dropout\n",
        "# )\n",
        "\n",
        "decoder = Decoder(\n",
        "    dec_feature_size = len(input_data),\n",
        "    dec_target_size = len(output_data),\n",
        "    hidden_size = hidden_size,\n",
        "    num_gru_layers = num_gru_layers,\n",
        "    dropout =  dropout\n",
        ")\n",
        "\n",
        "# model = Seq2SeqTeacherForce(encoder, decoder)\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "# model.load_state_dict(torch.load(f'./{model_filename}'))\n",
        "model.to(device)\n",
        "# loss_function = nn.MSELoss()\n",
        "loss_function = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c848f7be-9f82-49b5-af2e-f6f4d5684687",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "c848f7be-9f82-49b5-af2e-f6f4d5684687",
        "outputId": "5fafea26-0831-487b-fd31-9d7b578182fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "---------\n",
            "Train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 3/56 [00:58<17:11, 19.46s/it]\n",
            "2024/11/14 06:45:48 INFO mlflow.tracking._tracking_service.client: 🏃 View run nebulous-deer-955 at: https://dagshub.com/pranamodeling/seq2seq-gtd-6rm.mlflow/#/experiments/0/runs/380127740f024f228da70a3932a09b73.\n",
            "2024/11/14 06:45:48 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/pranamodeling/seq2seq-gtd-6rm.mlflow/#/experiments/0.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f973ae99f7d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {ix_epoch+1}\\n---------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-b149019935f7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(filenames, model, loss_function, optimizer, model_filename, batch_size, teacher_force_probability)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with mlflow.start_run() as run:\n",
        "  # mlflow.pytorch.autolog()\n",
        "\n",
        "  mlflow.log_param(\"encoder_length\", str(encoder_length))\n",
        "  mlflow.log_param(\"decoder_length\", decoder_length)\n",
        "  mlflow.log_param(\"hidden_size\", hidden_size)\n",
        "  mlflow.log_param(\"num_gru_layers\", num_gru_layers)\n",
        "  mlflow.log_param(\"dropout\", dropout)\n",
        "  mlflow.log_param(\"learning_rate\", learning_rate)\n",
        "  mlflow.log_param(\"summary\", summary(model))\n",
        "  # mlflow.log_param(\"teacher_force_probability\", teacher_force_probability)\n",
        "  mlflow.log_param(\"batch_size\", batch_size)\n",
        "\n",
        "  y_loss = {}  # loss history\n",
        "  y_loss['train'] = []\n",
        "  y_loss['val'] = []\n",
        "  # y_err = {}\n",
        "  # y_err['train'] = []\n",
        "  # y_err['val'] = []\n",
        "\n",
        "  x_epoch = []\n",
        "  fig = plt.figure()\n",
        "  # ax0 = fig.add_subplot(121, title=\"loss\")\n",
        "  # ax1 = fig.add_subplot(122, title=\"top1err\")\n",
        "\n",
        "\n",
        "  def draw_curve(current_epoch):\n",
        "      x_epoch.append(current_epoch)\n",
        "      plt.plot(x_epoch, y_loss['train'], 'bo-', label='train')\n",
        "      plt.plot(x_epoch, y_loss['val'], 'ro-', label='val')\n",
        "      # ax1.plot(x_epoch, y_err['train'], 'bo-', label='train')\n",
        "      # ax1.plot(x_epoch, y_err['val'], 'ro-', label='val')\n",
        "      if current_epoch == 0:\n",
        "          plt.legend()\n",
        "          # ax1.legend()\n",
        "      # fig.savefig(os.path.join('./lossGraphs', 'train.jpg'))\n",
        "\n",
        "\n",
        "  for ix_epoch in range(num_epoch):\n",
        "      print(f\"Epoch {ix_epoch+1}\\n---------\")\n",
        "      print(\"Train\")\n",
        "      train_loss = train_model(train_files, model, loss_function, optimizer=optimizer, model_filename=model_filename, batch_size=512)\n",
        "      print(\"Test\")\n",
        "      test_loss = test_model(test_files, model, loss_function, batch_size=1024)\n",
        "\n",
        "      mlflow.log_metric(\"train_loss\", train_loss, step=ix_epoch)\n",
        "      mlflow.log_metric(\"test_loss\", test_loss, step=ix_epoch)\n",
        "\n",
        "      y_loss['train'].append(train_loss)\n",
        "      y_loss['val'].append(test_loss)\n",
        "\n",
        "      clear_output(wait=True)\n",
        "      draw_curve(ix_epoch)\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "  mlflow.pytorch.log_model(model, \"model\")\n",
        "\n",
        "\n",
        "  model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
        "  loaded_model = mlflow.pytorch.load_model(model_uri)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ZUk4-nuyvzb",
      "metadata": {
        "id": "6ZUk4-nuyvzb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tZIuYOVSABYv",
      "metadata": {
        "id": "tZIuYOVSABYv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "Dv2cfrXpggbx",
      "metadata": {
        "id": "Dv2cfrXpggbx"
      },
      "source": [
        "### Обучение Seq2Seq с teacher force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f42383f-1957-4d87-8adf-8612a995c6b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f42383f-1957-4d87-8adf-8612a995c6b4",
        "outputId": "6621e0af-2e23-4d8e-e356-4f7b6466f60b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "Seq2SeqWithTeacherForce                  --\n",
              "├─Encoder: 1-1                           --\n",
              "│    └─GRU: 2-1                          818,688\n",
              "├─DecoderWithTeacherForce: 1-2           --\n",
              "│    └─GRU: 2-2                          818,688\n",
              "│    └─Linear: 2-3                       5,643\n",
              "=================================================================\n",
              "Total params: 1,643,019\n",
              "Trainable params: 1,643,019\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder_length = 60\n",
        "decoder_length = 300\n",
        "hidden_size = 512\n",
        "num_gru_layers = 1\n",
        "dropout = 0.\n",
        "learning_rate = 5e-4\n",
        "# teacher_force_probability = 0.5\n",
        "batch_size = 1024\n",
        "num_epoch = 10\n",
        "\n",
        "teacher_force_probability_list = [max(i/num_epoch, 0)\n",
        "for i in range(num_epoch, round(-num_epoch*0.3), -1)]\n",
        "\n",
        "current_dateTime = \"{:%d%m%y}\".format(datetime.now())\n",
        "model_filename = f\"seq2seqTF_{current_dateTime}.pt\"\n",
        "\n",
        "encoder = Encoder(\n",
        "    enc_feature_size = len(input_data)+len(output_data),\n",
        "    hidden_size = hidden_size,\n",
        "    num_gru_layers = num_gru_layers,\n",
        "    dropout =  dropout\n",
        ")\n",
        "\n",
        "decoder = DecoderWithTeacherForce(\n",
        "    dec_feature_size = len(input_data)+len(output_data),\n",
        "    dec_target_size = len(output_data),\n",
        "    hidden_size = hidden_size,\n",
        "    num_gru_layers = num_gru_layers,\n",
        "    dropout =  dropout\n",
        ")\n",
        "\n",
        "\n",
        "model = Seq2SeqWithTeacherForce(encoder, decoder)\n",
        "model.to(device)\n",
        "# loss_function = nn.MSELoss()\n",
        "loss_function = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VlAQBnvAh8Fj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "VlAQBnvAh8Fj",
        "outputId": "7ed7cce5-d3d8-4547-ef16-19aa857f1cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "---------\n",
            "Train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 12/56 [01:45<06:25,  8.77s/it]\n",
            "2024/11/14 07:33:58 INFO mlflow.tracking._tracking_service.client: 🏃 View run able-foal-302 at: https://dagshub.com/pranamodeling/seq2seq-gtd-6rm.mlflow/#/experiments/0/runs/bcb6a7c2c3464febb8b344b30874cdbf.\n",
            "2024/11/14 07:33:58 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/pranamodeling/seq2seq-gtd-6rm.mlflow/#/experiments/0.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-fa665593c273>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mteacher_force_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_force_probability_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix_epoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       train_loss = train_model(train_files, model,\n\u001b[0m\u001b[1;32m     37\u001b[0m                               \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-7f4157bf2968>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(filenames, model, loss_function, optimizer, model_filename, batch_size, teacher_force_probability)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             output, hidden = model(encoder_inputs, decoder_inputs,\n\u001b[0m\u001b[1;32m     34\u001b[0m                                    decoder_state_inputs, teacher_force_probability)\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-8d0b1a5a381d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc_inputs, dec_inputs, targets, teacher_force_probability)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_force_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-8d0b1a5a381d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, state_inputs, teacher_force_probability)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 (inputs[:,t,:][:,np.newaxis,:], outputs[t-1]), 2)\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_at_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             result = _VF.gru(\n\u001b[0m\u001b[1;32m   1393\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with mlflow.start_run() as run:\n",
        "\n",
        "  mlflow.log_param(\"encoder_length\", str(encoder_length))\n",
        "  mlflow.log_param(\"decoder_length\", decoder_length)\n",
        "  mlflow.log_param(\"hidden_size\", hidden_size)\n",
        "  mlflow.log_param(\"num_lstm_layers\", num_gru_layers)\n",
        "  # mlflow.log_param(\"dropout\", dropout)\n",
        "  mlflow.log_param(\"learning_rate\", learning_rate)\n",
        "  mlflow.log_param(\"summary\", summary(model))\n",
        "  # mlflow.log_param(\"teacher_force_probability\", teacher_force_probability)\n",
        "  mlflow.log_param(\"batch_size\", batch_size)\n",
        "\n",
        "  teacher_force_probability_list = [max(i/num_epoch, 0) for i in range(num_epoch, round(-num_epoch*0.3), -1)]\n",
        "\n",
        "  y_loss = {}  # loss history\n",
        "  y_loss['train'] = []\n",
        "  y_loss['val'] = []\n",
        "\n",
        "\n",
        "  x_epoch = []\n",
        "  fig = plt.figure()\n",
        "\n",
        "\n",
        "  def draw_curve(current_epoch):\n",
        "      x_epoch.append(current_epoch)\n",
        "      plt.plot(x_epoch, y_loss['train'], 'bo-', label='train')\n",
        "      plt.plot(x_epoch, y_loss['val'], 'ro-', label='val')\n",
        "      if current_epoch == 0:\n",
        "          plt.legend()\n",
        "\n",
        "  for ix_epoch in range(num_epoch):\n",
        "      print(f\"Epoch {ix_epoch+1}\\n---------\")\n",
        "      print(\"Train\")\n",
        "\n",
        "      teacher_force_probability = teacher_force_probability_list[ix_epoch]\n",
        "      train_loss = train_model(train_files, model,\n",
        "                              loss_function,\n",
        "                              optimizer=optimizer,\n",
        "                              model_filename=model_filename,\n",
        "                              batch_size=batch_size,\n",
        "                              teacher_force_probability=teacher_force_probability)\n",
        "      print(\"Test\")\n",
        "      test_loss = test_model(\n",
        "          test_files, model, loss_function, batch_size=batch_size)\n",
        "\n",
        "      mlflow.log_metric(\"train_loss\", train_loss, step=ix_epoch)\n",
        "      mlflow.log_metric(\"test_loss\", test_loss, step=ix_epoch)\n",
        "\n",
        "      y_loss['train'].append(train_loss)\n",
        "      y_loss['val'].append(test_loss)\n",
        "\n",
        "      clear_output(wait=True)\n",
        "      draw_curve(ix_epoch)\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "  mlflow.pytorch.log_model(model, \"model\")\n",
        "\n",
        "  model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
        "  loaded_model = mlflow.pytorch.load_model(model_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p1nzQBYJimUF",
      "metadata": {
        "id": "p1nzQBYJimUF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XoLIHjY22LIc",
        "VjfB7yRIbv7k"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f8b60dbd1344375949944ceb97c9ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3b475138e174bb38d57b5ec57eac548",
              "IPY_MODEL_b284b99d34cc4ec2aaae6889191f3f7e",
              "IPY_MODEL_83e819c5931548ad9cd732ace95b3a83"
            ],
            "layout": "IPY_MODEL_522699c00fca4c19a960aab008e9465b"
          }
        },
        "b3b475138e174bb38d57b5ec57eac548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a3c76976e9f4331b9ee2667f778cef3",
            "placeholder": "​",
            "style": "IPY_MODEL_8ef8ed65218a42eb855496abefbae9df",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "b284b99d34cc4ec2aaae6889191f3f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9821068505f54b32ad14f0e3a00bef60",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_550ce55299394f5aa8a34759b9d19b76",
            "value": 2
          }
        },
        "83e819c5931548ad9cd732ace95b3a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad0666be19ae4f7cb50030a13fb33a9f",
            "placeholder": "​",
            "style": "IPY_MODEL_f0405c38184c4e0ca79b04d88267c531",
            "value": " 2/2 [02:14&lt;00:00,  0.01it/s]"
          }
        },
        "522699c00fca4c19a960aab008e9465b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "7a3c76976e9f4331b9ee2667f778cef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ef8ed65218a42eb855496abefbae9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9821068505f54b32ad14f0e3a00bef60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550ce55299394f5aa8a34759b9d19b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad0666be19ae4f7cb50030a13fb33a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0405c38184c4e0ca79b04d88267c531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "399a69a50340447aad75bafeb7820a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fed53c7cfe02408793201bf035753142",
              "IPY_MODEL_295195a8000447fbbe169caf665be7fc",
              "IPY_MODEL_c292656bb1854c1c8ab8dae2b6ed8d57"
            ],
            "layout": "IPY_MODEL_f39d948a16494d7baace7a446ece711e"
          }
        },
        "fed53c7cfe02408793201bf035753142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c99e817d89646f69d27c38bd2c7d138",
            "placeholder": "​",
            "style": "IPY_MODEL_4b8ce11a5f384a4783701065a281db4e",
            "value": "Epoch 0:   0%"
          }
        },
        "295195a8000447fbbe169caf665be7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3306121696449d9bade84b5eb5a6dbd",
            "max": 320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2ed9763a13841aa9dd4e9a6cdec4107",
            "value": 0
          }
        },
        "c292656bb1854c1c8ab8dae2b6ed8d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_550e100b82be4a7bbb9677f8ee31a21e",
            "placeholder": "​",
            "style": "IPY_MODEL_0dfc4a5d7abe45919c0cd648c76aeb22",
            "value": " 0/320 [00:00&lt;?, ?it/s]"
          }
        },
        "f39d948a16494d7baace7a446ece711e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8c99e817d89646f69d27c38bd2c7d138": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8ce11a5f384a4783701065a281db4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3306121696449d9bade84b5eb5a6dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ed9763a13841aa9dd4e9a6cdec4107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "550e100b82be4a7bbb9677f8ee31a21e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dfc4a5d7abe45919c0cd648c76aeb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}